{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b43b62e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import optuna\n",
    "from optuna.trial import Trial\n",
    "from optuna.samplers import TPESampler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from typing import List, Any, Tuple\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5853fc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Loading\n",
    "X_model = pd.read_csv('X_model.csv')\n",
    "Y_model = pd.read_csv('Y_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "230e2d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gender  age_code  region_code  cGIT  tGIT    sGIT  tVAT    sVAT  cEntire  \\\n",
      "0       1        13            7   0.0   0.0     0.0   0.0     0.0      1.0   \n",
      "1       1         5            1   2.0   0.0    17.0   0.0   185.0     39.0   \n",
      "2       2         6            2   6.0   3.0  2253.0   0.0  1712.0     26.0   \n",
      "3       2         1            1   2.0   0.0   342.0   0.0     0.0      5.0   \n",
      "4       2         5            1   2.0   0.0   273.0   0.0   104.0     10.0   \n",
      "\n",
      "   tEntire  sEntire     rcGIT  rtGIT     rsGIT  rtVAT     rsVAT  \n",
      "0      1.0     93.0  0.000000    0.0  0.000000    0.0  0.000000  \n",
      "1      0.0    790.0  0.051282    0.0  0.021519    0.0  0.234177  \n",
      "2      3.0   5119.0  0.230769    1.0  0.440125    0.0  0.334440  \n",
      "3      0.0    647.0  0.400000    0.0  0.528594    0.0  0.000000  \n",
      "4      1.0    608.0  0.200000    0.0  0.449013    0.0  0.171053  \n"
     ]
    }
   ],
   "source": [
    "# Define preprocessors\n",
    "def preprocess(X: pd.DataFrame):\n",
    "    X = X.fillna(0)\n",
    "    # Create new dataframe from columns \"gender\", \"age_code\", and \"region_code\"\n",
    "    X_new = pd.DataFrame(X, columns=['gender', 'age_code', 'region_code'])\n",
    "    GIT_range = r\"202205[0-9]{2}\"\n",
    "    cGIT = np.sum(X.filter(regex=(\"c\" + GIT_range), axis=1).values, axis=1)\n",
    "    tGIT = np.sum(X.filter(regex=(\"t\" + GIT_range), axis=1).values, axis=1)\n",
    "    sGIT = np.sum(X.filter(regex=(\"s\" + GIT_range), axis=1).values, axis=1)\n",
    "\n",
    "    VAT_range = r\"20220[17](?:[01][0-9]|2[0-5])\"\n",
    "    tVAT = np.sum(X.filter(regex=(\"t\" + VAT_range), axis=1).values, axis=1)\n",
    "    sVAT = np.sum(X.filter(regex=(\"s\" + VAT_range), axis=1).values, axis=1)\n",
    "\n",
    "    entire_range = r\"2022[0-9]{4}\"\n",
    "    cEntire = np.sum(X.filter(regex=(\"c\" + entire_range), axis=1).values, axis=1)\n",
    "    tEntire = np.sum(X.filter(regex=(\"t\" + entire_range), axis=1).values, axis=1)\n",
    "    sEntire = np.sum(X.filter(regex=(\"s\" + entire_range), axis=1).values, axis=1)\n",
    "\n",
    "    rcGIT = np.divide(cGIT, cEntire)\n",
    "    rtGIT = np.divide(tGIT, tEntire)\n",
    "    rsGIT = np.divide(sGIT, sEntire)\n",
    "\n",
    "    rtVAT = np.divide(tVAT, tEntire)\n",
    "    rsVAT = np.divide(sVAT, sEntire)\n",
    "\n",
    "    X_new['cGIT'] = cGIT\n",
    "    X_new['tGIT'] = tGIT\n",
    "    X_new['sGIT'] = sGIT\n",
    "\n",
    "    X_new['tVAT'] = tVAT\n",
    "    X_new['sVAT'] = sVAT\n",
    "\n",
    "    X_new['cEntire'] = cEntire\n",
    "    X_new['tEntire'] = tEntire\n",
    "    X_new['sEntire'] = sEntire\n",
    "\n",
    "    X_new['rcGIT'] = rcGIT\n",
    "    X_new['rtGIT'] = rtGIT\n",
    "    X_new['rsGIT'] = rsGIT\n",
    "\n",
    "    X_new['rtVAT'] = rtVAT\n",
    "    X_new['rsVAT'] = rsVAT\n",
    "\n",
    "    X_new = X_new.fillna(0)\n",
    "    print(X_new.head())\n",
    "\n",
    "    return X_new\n",
    "# Preprocess\n",
    "X_processed = preprocess(X_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d545989f",
   "metadata": {},
   "outputs": [],
   "source": [
    "OL = [276935, 661865, 15127, 696728, 679738]\n",
    "X_processed.drop(OL,inplace=True)\n",
    "Y_model.drop(OL,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a405b26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac76e6b0f5cd4e0c9c68410a2fb3612a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=596, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=596\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.012488596029615604, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.012488596029615604\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.1315029324624064, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1315029324624064\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.13820667360294003, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.13820667360294003\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=596, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=596\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.012488596029615604, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.012488596029615604\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.1315029324624064, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1315029324624064\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.13820667360294003, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.13820667360294003\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=596, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=596\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.012488596029615604, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.012488596029615604\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.1315029324624064, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1315029324624064\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.13820667360294003, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.13820667360294003\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=596, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=596\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.012488596029615604, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.012488596029615604\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.1315029324624064, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1315029324624064\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.13820667360294003, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.13820667360294003\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=596, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=596\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.012488596029615604, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.012488596029615604\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.1315029324624064, subsample=1.0 will be ignored. Current value: bagging_fraction=0.1315029324624064\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.13820667360294003, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.13820667360294003\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=691, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=691\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001196296531252442, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001196296531252442\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.44712375757490586, subsample=1.0 will be ignored. Current value: bagging_fraction=0.44712375757490586\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.027253446721537542, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.027253446721537542\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=691, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=691\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001196296531252442, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001196296531252442\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.44712375757490586, subsample=1.0 will be ignored. Current value: bagging_fraction=0.44712375757490586\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.027253446721537542, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.027253446721537542\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=691, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=691\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001196296531252442, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001196296531252442\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.44712375757490586, subsample=1.0 will be ignored. Current value: bagging_fraction=0.44712375757490586\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.027253446721537542, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.027253446721537542\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=691, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=691\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001196296531252442, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001196296531252442\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.44712375757490586, subsample=1.0 will be ignored. Current value: bagging_fraction=0.44712375757490586\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.027253446721537542, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.027253446721537542\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=691, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=691\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.001196296531252442, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001196296531252442\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.44712375757490586, subsample=1.0 will be ignored. Current value: bagging_fraction=0.44712375757490586\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.027253446721537542, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.027253446721537542\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=653, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=653\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.03730932305276571, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03730932305276571\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6414969457588126, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6414969457588126\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16187214920147655, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16187214920147655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=653, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=653\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.03730932305276571, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03730932305276571\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6414969457588126, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6414969457588126\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16187214920147655, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16187214920147655\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=653, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=653\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.03730932305276571, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03730932305276571\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6414969457588126, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6414969457588126\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16187214920147655, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16187214920147655\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=653, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=653\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.03730932305276571, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03730932305276571\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6414969457588126, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6414969457588126\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16187214920147655, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16187214920147655\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=653, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=653\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.03730932305276571, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03730932305276571\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6414969457588126, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6414969457588126\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.16187214920147655, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.16187214920147655\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=345, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=345\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.224164500491251, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.224164500491251\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9179536228906514, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9179536228906514\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4029544452042022, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4029544452042022\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=345, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=345\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.224164500491251, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.224164500491251\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9179536228906514, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9179536228906514\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4029544452042022, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4029544452042022\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=345, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=345\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.224164500491251, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.224164500491251\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9179536228906514, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9179536228906514\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4029544452042022, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4029544452042022\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=345, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=345\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.224164500491251, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.224164500491251\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9179536228906514, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9179536228906514\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4029544452042022, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4029544452042022\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=345, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=345\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.224164500491251, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.224164500491251\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9179536228906514, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9179536228906514\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4029544452042022, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4029544452042022\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=287, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=287\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08851254702495535, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08851254702495535\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8364276859994654, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8364276859994654\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0028747232893556575, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0028747232893556575\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=287, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=287\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08851254702495535, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08851254702495535\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8364276859994654, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8364276859994654\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0028747232893556575, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0028747232893556575\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=287, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=287\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08851254702495535, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08851254702495535\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8364276859994654, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8364276859994654\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0028747232893556575, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0028747232893556575\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=287, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=287\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08851254702495535, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08851254702495535\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8364276859994654, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8364276859994654\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0028747232893556575, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0028747232893556575\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=287, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=287\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.08851254702495535, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08851254702495535\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8364276859994654, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8364276859994654\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0028747232893556575, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0028747232893556575\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=136, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=136\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.3211077016618837, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.3211077016618837\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3870872284784832, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3870872284784832\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4012497199962917, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4012497199962917\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=136, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=136\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.3211077016618837, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.3211077016618837\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3870872284784832, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3870872284784832\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4012497199962917, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4012497199962917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=136, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=136\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.3211077016618837, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.3211077016618837\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3870872284784832, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3870872284784832\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4012497199962917, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4012497199962917\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=136, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=136\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.3211077016618837, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.3211077016618837\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3870872284784832, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3870872284784832\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4012497199962917, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4012497199962917\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=136, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=136\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.3211077016618837, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.3211077016618837\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3870872284784832, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3870872284784832\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.4012497199962917, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.4012497199962917\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=465, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=465\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.1492967996386527, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1492967996386527\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.31207087883890006, subsample=1.0 will be ignored. Current value: bagging_fraction=0.31207087883890006\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.014632541608886709, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.014632541608886709\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=465, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=465\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.1492967996386527, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1492967996386527\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.31207087883890006, subsample=1.0 will be ignored. Current value: bagging_fraction=0.31207087883890006\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.014632541608886709, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.014632541608886709\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=465, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=465\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.1492967996386527, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1492967996386527\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.31207087883890006, subsample=1.0 will be ignored. Current value: bagging_fraction=0.31207087883890006\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.014632541608886709, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.014632541608886709\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=465, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=465\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.1492967996386527, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1492967996386527\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.31207087883890006, subsample=1.0 will be ignored. Current value: bagging_fraction=0.31207087883890006\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.014632541608886709, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.014632541608886709\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=465, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=465\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.1492967996386527, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1492967996386527\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.31207087883890006, subsample=1.0 will be ignored. Current value: bagging_fraction=0.31207087883890006\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.014632541608886709, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.014632541608886709\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=356, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=356\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7631742449487128, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7631742449487128\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7458727913200583, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7458727913200583\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03819430739425821, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03819430739425821\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=356, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=356\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7631742449487128, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7631742449487128\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7458727913200583, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7458727913200583\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03819430739425821, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03819430739425821\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=356, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=356\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7631742449487128, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7631742449487128\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7458727913200583, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7458727913200583\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03819430739425821, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03819430739425821\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=356, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=356\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7631742449487128, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7631742449487128\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7458727913200583, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7458727913200583\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03819430739425821, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03819430739425821\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=356, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=356\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.7631742449487128, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7631742449487128\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7458727913200583, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7458727913200583\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03819430739425821, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03819430739425821\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=229, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=229\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0033312851860212676, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0033312851860212676\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.42306731718008694, subsample=1.0 will be ignored. Current value: bagging_fraction=0.42306731718008694\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.004459304659759271, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004459304659759271\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=229, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=229\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0033312851860212676, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0033312851860212676\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.42306731718008694, subsample=1.0 will be ignored. Current value: bagging_fraction=0.42306731718008694\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.004459304659759271, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004459304659759271\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=229, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=229\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0033312851860212676, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0033312851860212676\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.42306731718008694, subsample=1.0 will be ignored. Current value: bagging_fraction=0.42306731718008694\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.004459304659759271, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004459304659759271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=229, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=229\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0033312851860212676, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0033312851860212676\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.42306731718008694, subsample=1.0 will be ignored. Current value: bagging_fraction=0.42306731718008694\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.004459304659759271, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004459304659759271\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=229, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=229\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0033312851860212676, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0033312851860212676\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.42306731718008694, subsample=1.0 will be ignored. Current value: bagging_fraction=0.42306731718008694\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.004459304659759271, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004459304659759271\n",
      "{'n_estimators': 162, 'max_depth': 11, 'learning_rate': 0.050917456979111125, 'num_leaves': 631, 'min_data_in_leaf': 759, 'max_bin': 284, 'lambda_l1': 1.5748112729766246, 'lambda_l2': 8.86176475299599, 'min_child_weight': 5, 'bagging_fraction': 0.39335063783856505, 'pos_bagging_fraction': 0.5105878967037487, 'neg_bagging_fraction': 0.9016688562057351}\n"
     ]
    }
   ],
   "source": [
    "#optimize by using optuna\n",
    "def optimizeLGBM(trial):\n",
    "    lgbm = LGBMClassifier(\n",
    "                          task = \"train\",\n",
    "                          objective = \"binary\", #cross-entropy\n",
    "#                           boosting = \"gdbt\", #rf\n",
    "                          n_estimators=trial.suggest_int('n_estimators',100,500),\n",
    "                          # to deal with overfitting, very important param\n",
    "                          max_depth = trial.suggest_int('max_depth',10,20),\n",
    "                          learning_rate = trial.suggest_float('learning_rate',0.02,0.1),\n",
    "                          num_leaves = trial.suggest_int('num_leaves',500,1000),\n",
    "                          min_data_in_leaf = trial.suggest_int('min_data_in_leaf',100,1000),\n",
    "                          metric = \"auc\",\n",
    "                          #if max_bin becomes small, the accuracy goes up\n",
    "                          max_bin = trial.suggest_int('max_bin',255,350),\n",
    "                          tree_learner = \"data\",\n",
    "                          lambda_l1 = trial.suggest_loguniform('lambda_l1', 1e-3, 10.0),\n",
    "                          lambda_l2 = trial.suggest_loguniform('lambda_l2', 1e-3, 10.0),\n",
    "                          # to deal with overfitting\n",
    "                          min_child_weight = trial.suggest_int('min_child_weight', 1, 10),\n",
    "                          random_state=100,\n",
    "                          #for bagging imbalanced\n",
    "                          bagging_fraction = trial.suggest_float('bagging_fraction', 0,1),\n",
    "                          pos_bagging_fraction = trial.suggest_float('pos_bagging_fraction', 0,1),\n",
    "                          neg_bagging_fraction = trial.suggest_float('neg_bagging_fraction', 0,1),\n",
    "                          categorical_feature = [0,1,2],\n",
    "#                           is_unbalance = True\n",
    "                          class_weight={0: 1, 1: 14.291397},\n",
    "         'feature_fraction': 0.95,\n",
    " 'drop_rate': 0.5917712341785191,\n",
    "         'bagging_seed': 42,\n",
    "         'verbosity': -1,\n",
    "        \n",
    "        \n",
    "#                           boosting = \"gdbt\", #rf\n",
    "#                           min_gain_to_split = ,\n",
    "#                           bagging_fraction = ,\n",
    "#                           early_stopping_round = ,\n",
    "\n",
    "    )\n",
    "    #cross validation K=5\n",
    "    score = cross_val_score(lgbm, X_processed, Y_model, cv=StratifiedKFold(n_splits=5, shuffle=True),\n",
    "                            scoring=\"roc_auc\")\n",
    "    return score.mean()\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "LGBM_study = optuna.create_study(direction='maximize')\n",
    "LGBM_study.optimize(optimizeLGBM, show_progress_bar=True, n_trials=10)\n",
    "\n",
    "# Print the best parameters\n",
    "print(LGBM_study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7030763f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply model and fit\n",
    "optimized_LGBM = LGBMClassifier(task = \"predict\",\n",
    "                          objective = \"binary\", # cross-entropy\n",
    "#                           boosting = gdbt, #rf\n",
    "                          n_estimators=LGBM_study.best_params['n_estimators'],\n",
    "                          # to deal with overfitting, very important param\n",
    "                          max_depth = LGBM_study.best_params['max_depth'],\n",
    "                          learning_rate = LGBM_study.best_params['learning_rate'], # if it becomes 0.01(maybe?)the result proba becomes extremely small\n",
    "                          num_leaves = LGBM_study.best_params['num_leaves'],\n",
    "                          min_data_in_leaf = LGBM_study.best_params['min_data_in_leaf'],\n",
    "                          metric = \"auc\",\n",
    "                          #if max_bin becomes small, the accuracy goes up\n",
    "                          max_bin = LGBM_study.best_params['max_bin'],\n",
    "                          tree_learner = \"data\",\n",
    "                          lambda_l1 = LGBM_study.best_params['lambda_l1'],\n",
    "                          lambda_l2 = LGBM_study.best_params['lambda_l2'],\n",
    "                          # to deal with overfitting\n",
    "                          min_child_weight = LGBM_study.best_params['min_child_weight'], #LGBM_study.best_params['min_child_weight']\n",
    "                          random_state=100,\n",
    "                          bagging_fraction = LGBM_study.best_params['bagging_fraction'],\n",
    "                          pos_bagging_fraction = LGBM_study.best_params['pos_bagging_fraction'],\n",
    "                          neg_bagging_fraction = LGBM_study.best_params['pos_bagging_fraction'],\n",
    "#                           is_unbalance = True\n",
    "                          categorical_feature = [0,1,2],\n",
    "                          class_weight={0: 1, 1: 14.291397}\n",
    "                               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8847eb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "Average ROC AUC Score 0.8789285922137167\n",
      "Standard Deviation of ROC AUC Score 0.001155013644822488\n",
      "[0.8793991  0.87737847 0.88084982 0.87848843 0.87852714]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 5 artists>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate\n",
    "scores = cross_val_score(\n",
    "    optimized_LGBM, \n",
    "    X_processed, \n",
    "    Y_model, \n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True\n",
    "                       ,random_state=100\n",
    "                      ),\n",
    "    scoring='roc_auc'\n",
    ")\n",
    "print(\"Average ROC AUC Score\", np.mean(scores))\n",
    "print(\"Standard Deviation of ROC AUC Score\", np.std(scores))\n",
    "# Plot 5 scores in bar plot\n",
    "print(scores)\n",
    "plt.bar(list(map(lambda i: f\"Fold #{i}\", range(1, 6))), scores)\n",
    "\n",
    "#0.8753111530570191\n",
    "#0.8756329404995423\n",
    "#0.8780611462672319 when iterate 10 times\n",
    "#0.8786665892827801 when iterate 100 times\n",
    "#0.8786365497775094 -> trial 7 when iterate 10 times\n",
    "#0.8789 -> original featured data is the best!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d43b3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gender  age_code  region_code  cGIT  tGIT   sGIT  tVAT    sVAT  cEntire  \\\n",
      "0       2         4            4   4.0   0.0   19.0   2.0   468.0     16.0   \n",
      "1       2        10           15   0.0   0.0    0.0   0.0     0.0      7.0   \n",
      "2       2         4            2   4.0   0.0  800.0   2.0  2719.0     48.0   \n",
      "3       1         8            1   1.0   0.0   50.0   0.0     0.0     13.0   \n",
      "4       2         8            2   0.0   0.0    0.0   1.0   488.0      1.0   \n",
      "\n",
      "   tEntire  sEntire     rcGIT  rtGIT     rsGIT     rtVAT     rsVAT  \n",
      "0      2.0   1187.0  0.250000    0.0  0.016007  1.000000  0.394271  \n",
      "1      0.0   1253.0  0.000000    0.0  0.000000  0.000000  0.000000  \n",
      "2      7.0   4502.0  0.083333    0.0  0.177699  0.285714  0.603954  \n",
      "3      0.0    979.0  0.076923    0.0  0.051073  0.000000  0.000000  \n",
      "4      1.0    488.0  0.000000    0.0  0.000000  1.000000  1.000000  \n"
     ]
    }
   ],
   "source": [
    "X_exam = pd.read_csv('X_exam.csv')\n",
    "X_exam_processed = preprocess(X_exam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4bf0e9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing...\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[1]\ttraining's auc: 0.872941\tvalid_1's auc: 0.869437\n",
      "[2]\ttraining's auc: 0.874139\tvalid_1's auc: 0.870655\n",
      "[3]\ttraining's auc: 0.874563\tvalid_1's auc: 0.870881\n",
      "[4]\ttraining's auc: 0.875613\tvalid_1's auc: 0.871899\n",
      "[5]\ttraining's auc: 0.875961\tvalid_1's auc: 0.87206\n",
      "[6]\ttraining's auc: 0.876235\tvalid_1's auc: 0.872344\n",
      "[7]\ttraining's auc: 0.876725\tvalid_1's auc: 0.872792\n",
      "[8]\ttraining's auc: 0.877264\tvalid_1's auc: 0.873274\n",
      "[9]\ttraining's auc: 0.87747\tvalid_1's auc: 0.873446\n",
      "[10]\ttraining's auc: 0.877841\tvalid_1's auc: 0.873696\n",
      "[11]\ttraining's auc: 0.878163\tvalid_1's auc: 0.873855\n",
      "[12]\ttraining's auc: 0.878397\tvalid_1's auc: 0.873934\n",
      "[13]\ttraining's auc: 0.878599\tvalid_1's auc: 0.874069\n",
      "[14]\ttraining's auc: 0.878701\tvalid_1's auc: 0.874116\n",
      "[15]\ttraining's auc: 0.878861\tvalid_1's auc: 0.874244\n",
      "[16]\ttraining's auc: 0.879082\tvalid_1's auc: 0.874419\n",
      "[17]\ttraining's auc: 0.879302\tvalid_1's auc: 0.874699\n",
      "[18]\ttraining's auc: 0.879593\tvalid_1's auc: 0.874912\n",
      "[19]\ttraining's auc: 0.879917\tvalid_1's auc: 0.875146\n",
      "[20]\ttraining's auc: 0.880132\tvalid_1's auc: 0.87532\n",
      "[21]\ttraining's auc: 0.880259\tvalid_1's auc: 0.875434\n",
      "[22]\ttraining's auc: 0.880413\tvalid_1's auc: 0.875542\n",
      "[23]\ttraining's auc: 0.880501\tvalid_1's auc: 0.875591\n",
      "[24]\ttraining's auc: 0.880634\tvalid_1's auc: 0.875626\n",
      "[25]\ttraining's auc: 0.880763\tvalid_1's auc: 0.875726\n",
      "[26]\ttraining's auc: 0.880851\tvalid_1's auc: 0.875757\n",
      "[27]\ttraining's auc: 0.88096\tvalid_1's auc: 0.875806\n",
      "[28]\ttraining's auc: 0.881044\tvalid_1's auc: 0.875849\n",
      "[29]\ttraining's auc: 0.881179\tvalid_1's auc: 0.875962\n",
      "[30]\ttraining's auc: 0.881359\tvalid_1's auc: 0.876079\n",
      "[31]\ttraining's auc: 0.88151\tvalid_1's auc: 0.876194\n",
      "[32]\ttraining's auc: 0.881648\tvalid_1's auc: 0.876259\n",
      "[33]\ttraining's auc: 0.881784\tvalid_1's auc: 0.876366\n",
      "[34]\ttraining's auc: 0.881886\tvalid_1's auc: 0.876419\n",
      "[35]\ttraining's auc: 0.881966\tvalid_1's auc: 0.876449\n",
      "[36]\ttraining's auc: 0.882062\tvalid_1's auc: 0.876532\n",
      "[37]\ttraining's auc: 0.882198\tvalid_1's auc: 0.876611\n",
      "[38]\ttraining's auc: 0.882369\tvalid_1's auc: 0.876709\n",
      "[39]\ttraining's auc: 0.882492\tvalid_1's auc: 0.876743\n",
      "[40]\ttraining's auc: 0.882572\tvalid_1's auc: 0.876787\n",
      "[41]\ttraining's auc: 0.882661\tvalid_1's auc: 0.876802\n",
      "[42]\ttraining's auc: 0.882802\tvalid_1's auc: 0.876895\n",
      "[43]\ttraining's auc: 0.882894\tvalid_1's auc: 0.876913\n",
      "[44]\ttraining's auc: 0.88303\tvalid_1's auc: 0.876961\n",
      "[45]\ttraining's auc: 0.883163\tvalid_1's auc: 0.877034\n",
      "[46]\ttraining's auc: 0.883336\tvalid_1's auc: 0.877109\n",
      "[47]\ttraining's auc: 0.883427\tvalid_1's auc: 0.877157\n",
      "[48]\ttraining's auc: 0.883614\tvalid_1's auc: 0.877212\n",
      "[49]\ttraining's auc: 0.883775\tvalid_1's auc: 0.877262\n",
      "[50]\ttraining's auc: 0.883873\tvalid_1's auc: 0.877298\n",
      "[51]\ttraining's auc: 0.883995\tvalid_1's auc: 0.877334\n",
      "[52]\ttraining's auc: 0.884116\tvalid_1's auc: 0.877394\n",
      "[53]\ttraining's auc: 0.884211\tvalid_1's auc: 0.877428\n",
      "[54]\ttraining's auc: 0.884297\tvalid_1's auc: 0.877433\n",
      "[55]\ttraining's auc: 0.884505\tvalid_1's auc: 0.877518\n",
      "[56]\ttraining's auc: 0.884611\tvalid_1's auc: 0.87755\n",
      "[57]\ttraining's auc: 0.88475\tvalid_1's auc: 0.877588\n",
      "[58]\ttraining's auc: 0.884834\tvalid_1's auc: 0.877595\n",
      "[59]\ttraining's auc: 0.884928\tvalid_1's auc: 0.877637\n",
      "[60]\ttraining's auc: 0.885029\tvalid_1's auc: 0.877681\n",
      "[61]\ttraining's auc: 0.885154\tvalid_1's auc: 0.877699\n",
      "[62]\ttraining's auc: 0.885292\tvalid_1's auc: 0.877743\n",
      "[63]\ttraining's auc: 0.885377\tvalid_1's auc: 0.877786\n",
      "[64]\ttraining's auc: 0.885545\tvalid_1's auc: 0.877802\n",
      "[65]\ttraining's auc: 0.885664\tvalid_1's auc: 0.877858\n",
      "[66]\ttraining's auc: 0.885722\tvalid_1's auc: 0.877869\n",
      "[67]\ttraining's auc: 0.885807\tvalid_1's auc: 0.877888\n",
      "[68]\ttraining's auc: 0.885906\tvalid_1's auc: 0.877934\n",
      "[69]\ttraining's auc: 0.885969\tvalid_1's auc: 0.87795\n",
      "[70]\ttraining's auc: 0.886038\tvalid_1's auc: 0.877985\n",
      "[71]\ttraining's auc: 0.886167\tvalid_1's auc: 0.878026\n",
      "[72]\ttraining's auc: 0.886335\tvalid_1's auc: 0.878084\n",
      "[73]\ttraining's auc: 0.886407\tvalid_1's auc: 0.878125\n",
      "[74]\ttraining's auc: 0.88646\tvalid_1's auc: 0.878146\n",
      "[75]\ttraining's auc: 0.88656\tvalid_1's auc: 0.878189\n",
      "[76]\ttraining's auc: 0.886822\tvalid_1's auc: 0.878291\n",
      "[77]\ttraining's auc: 0.886994\tvalid_1's auc: 0.878301\n",
      "[78]\ttraining's auc: 0.887207\tvalid_1's auc: 0.878378\n",
      "[79]\ttraining's auc: 0.887362\tvalid_1's auc: 0.878382\n",
      "[80]\ttraining's auc: 0.887497\tvalid_1's auc: 0.878391\n",
      "[81]\ttraining's auc: 0.887601\tvalid_1's auc: 0.878398\n",
      "[82]\ttraining's auc: 0.887769\tvalid_1's auc: 0.878439\n",
      "[83]\ttraining's auc: 0.887891\tvalid_1's auc: 0.878482\n",
      "[84]\ttraining's auc: 0.88802\tvalid_1's auc: 0.878522\n",
      "[85]\ttraining's auc: 0.888112\tvalid_1's auc: 0.878553\n",
      "[86]\ttraining's auc: 0.88819\tvalid_1's auc: 0.878566\n",
      "[87]\ttraining's auc: 0.888277\tvalid_1's auc: 0.878586\n",
      "[88]\ttraining's auc: 0.888369\tvalid_1's auc: 0.878601\n",
      "[89]\ttraining's auc: 0.888422\tvalid_1's auc: 0.878616\n",
      "[90]\ttraining's auc: 0.888522\tvalid_1's auc: 0.87864\n",
      "[91]\ttraining's auc: 0.888653\tvalid_1's auc: 0.878663\n",
      "[92]\ttraining's auc: 0.888735\tvalid_1's auc: 0.87867\n",
      "[93]\ttraining's auc: 0.888868\tvalid_1's auc: 0.878699\n",
      "[94]\ttraining's auc: 0.888959\tvalid_1's auc: 0.878709\n",
      "[95]\ttraining's auc: 0.889084\tvalid_1's auc: 0.87875\n",
      "[96]\ttraining's auc: 0.889154\tvalid_1's auc: 0.878757\n",
      "[97]\ttraining's auc: 0.88921\tvalid_1's auc: 0.878756\n",
      "[98]\ttraining's auc: 0.889257\tvalid_1's auc: 0.878766\n",
      "[99]\ttraining's auc: 0.889344\tvalid_1's auc: 0.878777\n",
      "[100]\ttraining's auc: 0.889407\tvalid_1's auc: 0.878788\n",
      "[101]\ttraining's auc: 0.889508\tvalid_1's auc: 0.8788\n",
      "[102]\ttraining's auc: 0.889566\tvalid_1's auc: 0.878797\n",
      "[103]\ttraining's auc: 0.889583\tvalid_1's auc: 0.878795\n",
      "[104]\ttraining's auc: 0.889641\tvalid_1's auc: 0.878794\n",
      "[105]\ttraining's auc: 0.889769\tvalid_1's auc: 0.878808\n",
      "[106]\ttraining's auc: 0.889816\tvalid_1's auc: 0.878829\n",
      "[107]\ttraining's auc: 0.889867\tvalid_1's auc: 0.878843\n",
      "[108]\ttraining's auc: 0.889931\tvalid_1's auc: 0.878851\n",
      "[109]\ttraining's auc: 0.889972\tvalid_1's auc: 0.878861\n",
      "[110]\ttraining's auc: 0.890015\tvalid_1's auc: 0.878875\n",
      "[111]\ttraining's auc: 0.890033\tvalid_1's auc: 0.878872\n",
      "[112]\ttraining's auc: 0.89006\tvalid_1's auc: 0.878884\n",
      "[113]\ttraining's auc: 0.89013\tvalid_1's auc: 0.878885\n",
      "[114]\ttraining's auc: 0.890156\tvalid_1's auc: 0.878899\n",
      "[115]\ttraining's auc: 0.890235\tvalid_1's auc: 0.8789\n",
      "[116]\ttraining's auc: 0.890266\tvalid_1's auc: 0.878906\n",
      "[117]\ttraining's auc: 0.890328\tvalid_1's auc: 0.878906\n",
      "[118]\ttraining's auc: 0.890401\tvalid_1's auc: 0.878899\n",
      "[119]\ttraining's auc: 0.890426\tvalid_1's auc: 0.878916\n",
      "[120]\ttraining's auc: 0.890473\tvalid_1's auc: 0.878917\n",
      "[121]\ttraining's auc: 0.890546\tvalid_1's auc: 0.878928\n",
      "[122]\ttraining's auc: 0.890568\tvalid_1's auc: 0.87893\n",
      "[123]\ttraining's auc: 0.8906\tvalid_1's auc: 0.878944\n",
      "[124]\ttraining's auc: 0.890626\tvalid_1's auc: 0.878947\n",
      "[125]\ttraining's auc: 0.890656\tvalid_1's auc: 0.878948\n",
      "[126]\ttraining's auc: 0.890685\tvalid_1's auc: 0.878953\n",
      "[127]\ttraining's auc: 0.890758\tvalid_1's auc: 0.878961\n",
      "[128]\ttraining's auc: 0.890816\tvalid_1's auc: 0.878963\n",
      "[129]\ttraining's auc: 0.890852\tvalid_1's auc: 0.878967\n",
      "[130]\ttraining's auc: 0.890979\tvalid_1's auc: 0.878997\n",
      "[131]\ttraining's auc: 0.891077\tvalid_1's auc: 0.878994\n",
      "[132]\ttraining's auc: 0.891109\tvalid_1's auc: 0.878998\n",
      "[133]\ttraining's auc: 0.891282\tvalid_1's auc: 0.87898\n",
      "[134]\ttraining's auc: 0.891378\tvalid_1's auc: 0.87899\n",
      "[135]\ttraining's auc: 0.891407\tvalid_1's auc: 0.879\n",
      "[136]\ttraining's auc: 0.89148\tvalid_1's auc: 0.878993\n",
      "[137]\ttraining's auc: 0.891508\tvalid_1's auc: 0.878989\n",
      "[138]\ttraining's auc: 0.891563\tvalid_1's auc: 0.878986\n",
      "[139]\ttraining's auc: 0.891661\tvalid_1's auc: 0.878986\n",
      "[140]\ttraining's auc: 0.891736\tvalid_1's auc: 0.878973\n",
      "[141]\ttraining's auc: 0.891789\tvalid_1's auc: 0.878975\n",
      "[142]\ttraining's auc: 0.891816\tvalid_1's auc: 0.878977\n",
      "[143]\ttraining's auc: 0.891896\tvalid_1's auc: 0.878973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[144]\ttraining's auc: 0.89199\tvalid_1's auc: 0.878978\n",
      "[145]\ttraining's auc: 0.892075\tvalid_1's auc: 0.878974\n",
      "[146]\ttraining's auc: 0.892102\tvalid_1's auc: 0.878984\n",
      "[147]\ttraining's auc: 0.892163\tvalid_1's auc: 0.878992\n",
      "[148]\ttraining's auc: 0.892204\tvalid_1's auc: 0.878983\n",
      "[149]\ttraining's auc: 0.892233\tvalid_1's auc: 0.878976\n",
      "[150]\ttraining's auc: 0.892318\tvalid_1's auc: 0.878974\n",
      "[151]\ttraining's auc: 0.892403\tvalid_1's auc: 0.878968\n",
      "[152]\ttraining's auc: 0.892457\tvalid_1's auc: 0.878959\n",
      "[153]\ttraining's auc: 0.892501\tvalid_1's auc: 0.878959\n",
      "[154]\ttraining's auc: 0.892546\tvalid_1's auc: 0.878979\n",
      "[155]\ttraining's auc: 0.892654\tvalid_1's auc: 0.87898\n",
      "[156]\ttraining's auc: 0.892741\tvalid_1's auc: 0.878966\n",
      "[157]\ttraining's auc: 0.892802\tvalid_1's auc: 0.878962\n",
      "[158]\ttraining's auc: 0.892895\tvalid_1's auc: 0.878968\n",
      "[159]\ttraining's auc: 0.892922\tvalid_1's auc: 0.878985\n",
      "[160]\ttraining's auc: 0.893005\tvalid_1's auc: 0.878999\n",
      "[161]\ttraining's auc: 0.893042\tvalid_1's auc: 0.879004\n",
      "[162]\ttraining's auc: 0.893162\tvalid_1's auc: 0.878977\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[1]\ttraining's auc: 0.872794\tvalid_1's auc: 0.868326\n",
      "[2]\ttraining's auc: 0.874793\tvalid_1's auc: 0.86977\n",
      "[3]\ttraining's auc: 0.875364\tvalid_1's auc: 0.87014\n",
      "[4]\ttraining's auc: 0.876201\tvalid_1's auc: 0.871\n",
      "[5]\ttraining's auc: 0.876451\tvalid_1's auc: 0.871276\n",
      "[6]\ttraining's auc: 0.876906\tvalid_1's auc: 0.87157\n",
      "[7]\ttraining's auc: 0.877613\tvalid_1's auc: 0.871928\n",
      "[8]\ttraining's auc: 0.878072\tvalid_1's auc: 0.872285\n",
      "[9]\ttraining's auc: 0.878258\tvalid_1's auc: 0.872398\n",
      "[10]\ttraining's auc: 0.878559\tvalid_1's auc: 0.872619\n",
      "[11]\ttraining's auc: 0.878802\tvalid_1's auc: 0.872713\n",
      "[12]\ttraining's auc: 0.878989\tvalid_1's auc: 0.872847\n",
      "[13]\ttraining's auc: 0.879211\tvalid_1's auc: 0.873038\n",
      "[14]\ttraining's auc: 0.879423\tvalid_1's auc: 0.873134\n",
      "[15]\ttraining's auc: 0.879596\tvalid_1's auc: 0.873322\n",
      "[16]\ttraining's auc: 0.879764\tvalid_1's auc: 0.873473\n",
      "[17]\ttraining's auc: 0.879945\tvalid_1's auc: 0.873582\n",
      "[18]\ttraining's auc: 0.880173\tvalid_1's auc: 0.873675\n",
      "[19]\ttraining's auc: 0.880339\tvalid_1's auc: 0.873733\n",
      "[20]\ttraining's auc: 0.880493\tvalid_1's auc: 0.873798\n",
      "[21]\ttraining's auc: 0.880686\tvalid_1's auc: 0.873866\n",
      "[22]\ttraining's auc: 0.880811\tvalid_1's auc: 0.873955\n",
      "[23]\ttraining's auc: 0.880944\tvalid_1's auc: 0.874037\n",
      "[24]\ttraining's auc: 0.881051\tvalid_1's auc: 0.874094\n",
      "[25]\ttraining's auc: 0.881197\tvalid_1's auc: 0.87417\n",
      "[26]\ttraining's auc: 0.881306\tvalid_1's auc: 0.874232\n",
      "[27]\ttraining's auc: 0.881394\tvalid_1's auc: 0.874266\n",
      "[28]\ttraining's auc: 0.881543\tvalid_1's auc: 0.874316\n",
      "[29]\ttraining's auc: 0.881735\tvalid_1's auc: 0.874425\n",
      "[30]\ttraining's auc: 0.881872\tvalid_1's auc: 0.87446\n",
      "[31]\ttraining's auc: 0.882052\tvalid_1's auc: 0.87452\n",
      "[32]\ttraining's auc: 0.882179\tvalid_1's auc: 0.874564\n",
      "[33]\ttraining's auc: 0.882285\tvalid_1's auc: 0.874623\n",
      "[34]\ttraining's auc: 0.882529\tvalid_1's auc: 0.874757\n",
      "[35]\ttraining's auc: 0.882673\tvalid_1's auc: 0.874793\n",
      "[36]\ttraining's auc: 0.882809\tvalid_1's auc: 0.874881\n",
      "[37]\ttraining's auc: 0.882947\tvalid_1's auc: 0.874897\n",
      "[38]\ttraining's auc: 0.882984\tvalid_1's auc: 0.87491\n",
      "[39]\ttraining's auc: 0.883092\tvalid_1's auc: 0.874941\n",
      "[40]\ttraining's auc: 0.883278\tvalid_1's auc: 0.875035\n",
      "[41]\ttraining's auc: 0.883405\tvalid_1's auc: 0.875127\n",
      "[42]\ttraining's auc: 0.883551\tvalid_1's auc: 0.875183\n",
      "[43]\ttraining's auc: 0.883738\tvalid_1's auc: 0.875247\n",
      "[44]\ttraining's auc: 0.883838\tvalid_1's auc: 0.875277\n",
      "[45]\ttraining's auc: 0.883998\tvalid_1's auc: 0.875352\n",
      "[46]\ttraining's auc: 0.884091\tvalid_1's auc: 0.875378\n",
      "[47]\ttraining's auc: 0.884243\tvalid_1's auc: 0.87542\n",
      "[48]\ttraining's auc: 0.884378\tvalid_1's auc: 0.875449\n",
      "[49]\ttraining's auc: 0.884455\tvalid_1's auc: 0.875475\n",
      "[50]\ttraining's auc: 0.884518\tvalid_1's auc: 0.875497\n",
      "[51]\ttraining's auc: 0.884599\tvalid_1's auc: 0.875502\n",
      "[52]\ttraining's auc: 0.884765\tvalid_1's auc: 0.875563\n",
      "[53]\ttraining's auc: 0.884875\tvalid_1's auc: 0.875578\n",
      "[54]\ttraining's auc: 0.884998\tvalid_1's auc: 0.875611\n",
      "[55]\ttraining's auc: 0.885058\tvalid_1's auc: 0.87564\n",
      "[56]\ttraining's auc: 0.885239\tvalid_1's auc: 0.8757\n",
      "[57]\ttraining's auc: 0.885321\tvalid_1's auc: 0.875747\n",
      "[58]\ttraining's auc: 0.885442\tvalid_1's auc: 0.875779\n",
      "[59]\ttraining's auc: 0.885518\tvalid_1's auc: 0.875815\n",
      "[60]\ttraining's auc: 0.885663\tvalid_1's auc: 0.875846\n",
      "[61]\ttraining's auc: 0.885789\tvalid_1's auc: 0.875888\n",
      "[62]\ttraining's auc: 0.885973\tvalid_1's auc: 0.875912\n",
      "[63]\ttraining's auc: 0.886067\tvalid_1's auc: 0.875953\n",
      "[64]\ttraining's auc: 0.886204\tvalid_1's auc: 0.875989\n",
      "[65]\ttraining's auc: 0.886289\tvalid_1's auc: 0.876009\n",
      "[66]\ttraining's auc: 0.886391\tvalid_1's auc: 0.876001\n",
      "[67]\ttraining's auc: 0.886575\tvalid_1's auc: 0.876027\n",
      "[68]\ttraining's auc: 0.886728\tvalid_1's auc: 0.876055\n",
      "[69]\ttraining's auc: 0.88688\tvalid_1's auc: 0.876084\n",
      "[70]\ttraining's auc: 0.886945\tvalid_1's auc: 0.876096\n",
      "[71]\ttraining's auc: 0.887056\tvalid_1's auc: 0.876123\n",
      "[72]\ttraining's auc: 0.887146\tvalid_1's auc: 0.876144\n",
      "[73]\ttraining's auc: 0.887203\tvalid_1's auc: 0.876168\n",
      "[74]\ttraining's auc: 0.887302\tvalid_1's auc: 0.87622\n",
      "[75]\ttraining's auc: 0.887416\tvalid_1's auc: 0.87626\n",
      "[76]\ttraining's auc: 0.887529\tvalid_1's auc: 0.876281\n",
      "[77]\ttraining's auc: 0.887664\tvalid_1's auc: 0.876322\n",
      "[78]\ttraining's auc: 0.887748\tvalid_1's auc: 0.876355\n",
      "[79]\ttraining's auc: 0.887864\tvalid_1's auc: 0.876369\n",
      "[80]\ttraining's auc: 0.887948\tvalid_1's auc: 0.876392\n",
      "[81]\ttraining's auc: 0.888074\tvalid_1's auc: 0.876382\n",
      "[82]\ttraining's auc: 0.888151\tvalid_1's auc: 0.876429\n",
      "[83]\ttraining's auc: 0.888256\tvalid_1's auc: 0.876444\n",
      "[84]\ttraining's auc: 0.888331\tvalid_1's auc: 0.876467\n",
      "[85]\ttraining's auc: 0.888379\tvalid_1's auc: 0.876482\n",
      "[86]\ttraining's auc: 0.888422\tvalid_1's auc: 0.876489\n",
      "[87]\ttraining's auc: 0.888518\tvalid_1's auc: 0.87654\n",
      "[88]\ttraining's auc: 0.888639\tvalid_1's auc: 0.876565\n",
      "[89]\ttraining's auc: 0.88871\tvalid_1's auc: 0.876565\n",
      "[90]\ttraining's auc: 0.888757\tvalid_1's auc: 0.876591\n",
      "[91]\ttraining's auc: 0.888831\tvalid_1's auc: 0.876614\n",
      "[92]\ttraining's auc: 0.888893\tvalid_1's auc: 0.87663\n",
      "[93]\ttraining's auc: 0.888977\tvalid_1's auc: 0.876656\n",
      "[94]\ttraining's auc: 0.889051\tvalid_1's auc: 0.876664\n",
      "[95]\ttraining's auc: 0.889139\tvalid_1's auc: 0.876668\n",
      "[96]\ttraining's auc: 0.889206\tvalid_1's auc: 0.876681\n",
      "[97]\ttraining's auc: 0.889306\tvalid_1's auc: 0.87669\n",
      "[98]\ttraining's auc: 0.889419\tvalid_1's auc: 0.876711\n",
      "[99]\ttraining's auc: 0.889492\tvalid_1's auc: 0.876741\n",
      "[100]\ttraining's auc: 0.889534\tvalid_1's auc: 0.876756\n",
      "[101]\ttraining's auc: 0.889614\tvalid_1's auc: 0.876784\n",
      "[102]\ttraining's auc: 0.889703\tvalid_1's auc: 0.876805\n",
      "[103]\ttraining's auc: 0.88976\tvalid_1's auc: 0.876818\n",
      "[104]\ttraining's auc: 0.889835\tvalid_1's auc: 0.87682\n",
      "[105]\ttraining's auc: 0.889906\tvalid_1's auc: 0.876838\n",
      "[106]\ttraining's auc: 0.889946\tvalid_1's auc: 0.876835\n",
      "[107]\ttraining's auc: 0.889993\tvalid_1's auc: 0.876847\n",
      "[108]\ttraining's auc: 0.89007\tvalid_1's auc: 0.876868\n",
      "[109]\ttraining's auc: 0.890098\tvalid_1's auc: 0.876873\n",
      "[110]\ttraining's auc: 0.890237\tvalid_1's auc: 0.876901\n",
      "[111]\ttraining's auc: 0.890317\tvalid_1's auc: 0.876921\n",
      "[112]\ttraining's auc: 0.890368\tvalid_1's auc: 0.876925\n",
      "[113]\ttraining's auc: 0.890405\tvalid_1's auc: 0.876918\n",
      "[114]\ttraining's auc: 0.890461\tvalid_1's auc: 0.876915\n",
      "[115]\ttraining's auc: 0.890511\tvalid_1's auc: 0.876919\n",
      "[116]\ttraining's auc: 0.890562\tvalid_1's auc: 0.876931\n",
      "[117]\ttraining's auc: 0.89062\tvalid_1's auc: 0.876938\n",
      "[118]\ttraining's auc: 0.890661\tvalid_1's auc: 0.87695\n",
      "[119]\ttraining's auc: 0.89085\tvalid_1's auc: 0.876971\n",
      "[120]\ttraining's auc: 0.890927\tvalid_1's auc: 0.876987\n",
      "[121]\ttraining's auc: 0.890964\tvalid_1's auc: 0.876992\n",
      "[122]\ttraining's auc: 0.891024\tvalid_1's auc: 0.876996\n",
      "[123]\ttraining's auc: 0.89109\tvalid_1's auc: 0.877004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[124]\ttraining's auc: 0.891124\tvalid_1's auc: 0.877008\n",
      "[125]\ttraining's auc: 0.891162\tvalid_1's auc: 0.87702\n",
      "[126]\ttraining's auc: 0.891222\tvalid_1's auc: 0.877023\n",
      "[127]\ttraining's auc: 0.891296\tvalid_1's auc: 0.87701\n",
      "[128]\ttraining's auc: 0.891333\tvalid_1's auc: 0.877007\n",
      "[129]\ttraining's auc: 0.891434\tvalid_1's auc: 0.876992\n",
      "[130]\ttraining's auc: 0.891473\tvalid_1's auc: 0.877001\n",
      "[131]\ttraining's auc: 0.891515\tvalid_1's auc: 0.876998\n",
      "[132]\ttraining's auc: 0.891542\tvalid_1's auc: 0.877001\n",
      "[133]\ttraining's auc: 0.891629\tvalid_1's auc: 0.876989\n",
      "[134]\ttraining's auc: 0.891728\tvalid_1's auc: 0.877008\n",
      "[135]\ttraining's auc: 0.891841\tvalid_1's auc: 0.876998\n",
      "[136]\ttraining's auc: 0.891988\tvalid_1's auc: 0.877005\n",
      "[137]\ttraining's auc: 0.892104\tvalid_1's auc: 0.877014\n",
      "[138]\ttraining's auc: 0.892199\tvalid_1's auc: 0.877026\n",
      "[139]\ttraining's auc: 0.892265\tvalid_1's auc: 0.877031\n",
      "[140]\ttraining's auc: 0.8923\tvalid_1's auc: 0.877027\n",
      "[141]\ttraining's auc: 0.892506\tvalid_1's auc: 0.877057\n",
      "[142]\ttraining's auc: 0.892582\tvalid_1's auc: 0.877072\n",
      "[143]\ttraining's auc: 0.89262\tvalid_1's auc: 0.877085\n",
      "[144]\ttraining's auc: 0.892658\tvalid_1's auc: 0.877093\n",
      "[145]\ttraining's auc: 0.892692\tvalid_1's auc: 0.877089\n",
      "[146]\ttraining's auc: 0.892749\tvalid_1's auc: 0.877087\n",
      "[147]\ttraining's auc: 0.892839\tvalid_1's auc: 0.877088\n",
      "[148]\ttraining's auc: 0.892877\tvalid_1's auc: 0.877085\n",
      "[149]\ttraining's auc: 0.892971\tvalid_1's auc: 0.877064\n",
      "[150]\ttraining's auc: 0.893001\tvalid_1's auc: 0.877058\n",
      "[151]\ttraining's auc: 0.893235\tvalid_1's auc: 0.877078\n",
      "[152]\ttraining's auc: 0.893272\tvalid_1's auc: 0.877072\n",
      "[153]\ttraining's auc: 0.893337\tvalid_1's auc: 0.877074\n",
      "[154]\ttraining's auc: 0.893435\tvalid_1's auc: 0.877066\n",
      "[155]\ttraining's auc: 0.893483\tvalid_1's auc: 0.877078\n",
      "[156]\ttraining's auc: 0.893539\tvalid_1's auc: 0.877067\n",
      "[157]\ttraining's auc: 0.893655\tvalid_1's auc: 0.877046\n",
      "[158]\ttraining's auc: 0.893765\tvalid_1's auc: 0.877034\n",
      "[159]\ttraining's auc: 0.893808\tvalid_1's auc: 0.877039\n",
      "[160]\ttraining's auc: 0.893947\tvalid_1's auc: 0.877046\n",
      "[161]\ttraining's auc: 0.894044\tvalid_1's auc: 0.877055\n",
      "[162]\ttraining's auc: 0.894304\tvalid_1's auc: 0.87707\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[1]\ttraining's auc: 0.873265\tvalid_1's auc: 0.869911\n",
      "[2]\ttraining's auc: 0.87468\tvalid_1's auc: 0.871069\n",
      "[3]\ttraining's auc: 0.876065\tvalid_1's auc: 0.871994\n",
      "[4]\ttraining's auc: 0.876239\tvalid_1's auc: 0.872144\n",
      "[5]\ttraining's auc: 0.876434\tvalid_1's auc: 0.872423\n",
      "[6]\ttraining's auc: 0.877083\tvalid_1's auc: 0.873004\n",
      "[7]\ttraining's auc: 0.877293\tvalid_1's auc: 0.873253\n",
      "[8]\ttraining's auc: 0.877649\tvalid_1's auc: 0.873463\n",
      "[9]\ttraining's auc: 0.877958\tvalid_1's auc: 0.873708\n",
      "[10]\ttraining's auc: 0.877979\tvalid_1's auc: 0.873735\n",
      "[11]\ttraining's auc: 0.878293\tvalid_1's auc: 0.874085\n",
      "[12]\ttraining's auc: 0.878557\tvalid_1's auc: 0.874313\n",
      "[13]\ttraining's auc: 0.878644\tvalid_1's auc: 0.874413\n",
      "[14]\ttraining's auc: 0.878926\tvalid_1's auc: 0.874622\n",
      "[15]\ttraining's auc: 0.879263\tvalid_1's auc: 0.874935\n",
      "[16]\ttraining's auc: 0.879463\tvalid_1's auc: 0.875011\n",
      "[17]\ttraining's auc: 0.879647\tvalid_1's auc: 0.875164\n",
      "[18]\ttraining's auc: 0.879763\tvalid_1's auc: 0.875179\n",
      "[19]\ttraining's auc: 0.879905\tvalid_1's auc: 0.875258\n",
      "[20]\ttraining's auc: 0.880076\tvalid_1's auc: 0.875342\n",
      "[21]\ttraining's auc: 0.880234\tvalid_1's auc: 0.875442\n",
      "[22]\ttraining's auc: 0.880387\tvalid_1's auc: 0.87557\n",
      "[23]\ttraining's auc: 0.880515\tvalid_1's auc: 0.875675\n",
      "[24]\ttraining's auc: 0.880678\tvalid_1's auc: 0.875741\n",
      "[25]\ttraining's auc: 0.880837\tvalid_1's auc: 0.875845\n",
      "[26]\ttraining's auc: 0.880986\tvalid_1's auc: 0.875953\n",
      "[27]\ttraining's auc: 0.881091\tvalid_1's auc: 0.876054\n",
      "[28]\ttraining's auc: 0.881201\tvalid_1's auc: 0.876149\n",
      "[29]\ttraining's auc: 0.881378\tvalid_1's auc: 0.876252\n",
      "[30]\ttraining's auc: 0.881533\tvalid_1's auc: 0.876305\n",
      "[31]\ttraining's auc: 0.881674\tvalid_1's auc: 0.876391\n",
      "[32]\ttraining's auc: 0.881777\tvalid_1's auc: 0.876449\n",
      "[33]\ttraining's auc: 0.881955\tvalid_1's auc: 0.876514\n",
      "[34]\ttraining's auc: 0.882052\tvalid_1's auc: 0.876544\n",
      "[35]\ttraining's auc: 0.882206\tvalid_1's auc: 0.876635\n",
      "[36]\ttraining's auc: 0.882306\tvalid_1's auc: 0.87664\n",
      "[37]\ttraining's auc: 0.882456\tvalid_1's auc: 0.876682\n",
      "[38]\ttraining's auc: 0.88258\tvalid_1's auc: 0.87675\n",
      "[39]\ttraining's auc: 0.882688\tvalid_1's auc: 0.87683\n",
      "[40]\ttraining's auc: 0.882801\tvalid_1's auc: 0.876847\n",
      "[41]\ttraining's auc: 0.882888\tvalid_1's auc: 0.876928\n",
      "[42]\ttraining's auc: 0.882986\tvalid_1's auc: 0.876994\n",
      "[43]\ttraining's auc: 0.883082\tvalid_1's auc: 0.877026\n",
      "[44]\ttraining's auc: 0.883271\tvalid_1's auc: 0.877121\n",
      "[45]\ttraining's auc: 0.883474\tvalid_1's auc: 0.877236\n",
      "[46]\ttraining's auc: 0.883565\tvalid_1's auc: 0.877287\n",
      "[47]\ttraining's auc: 0.883668\tvalid_1's auc: 0.877361\n",
      "[48]\ttraining's auc: 0.883796\tvalid_1's auc: 0.877438\n",
      "[49]\ttraining's auc: 0.883931\tvalid_1's auc: 0.877492\n",
      "[50]\ttraining's auc: 0.884056\tvalid_1's auc: 0.877545\n",
      "[51]\ttraining's auc: 0.884187\tvalid_1's auc: 0.877589\n",
      "[52]\ttraining's auc: 0.88432\tvalid_1's auc: 0.877644\n",
      "[53]\ttraining's auc: 0.884466\tvalid_1's auc: 0.877674\n",
      "[54]\ttraining's auc: 0.884565\tvalid_1's auc: 0.877718\n",
      "[55]\ttraining's auc: 0.884662\tvalid_1's auc: 0.877744\n",
      "[56]\ttraining's auc: 0.88476\tvalid_1's auc: 0.877778\n",
      "[57]\ttraining's auc: 0.884875\tvalid_1's auc: 0.877823\n",
      "[58]\ttraining's auc: 0.884969\tvalid_1's auc: 0.877862\n",
      "[59]\ttraining's auc: 0.885131\tvalid_1's auc: 0.877901\n",
      "[60]\ttraining's auc: 0.885235\tvalid_1's auc: 0.877938\n",
      "[61]\ttraining's auc: 0.885411\tvalid_1's auc: 0.878009\n",
      "[62]\ttraining's auc: 0.885538\tvalid_1's auc: 0.878048\n",
      "[63]\ttraining's auc: 0.885635\tvalid_1's auc: 0.878098\n",
      "[64]\ttraining's auc: 0.885689\tvalid_1's auc: 0.878113\n",
      "[65]\ttraining's auc: 0.885804\tvalid_1's auc: 0.878131\n",
      "[66]\ttraining's auc: 0.885875\tvalid_1's auc: 0.878123\n",
      "[67]\ttraining's auc: 0.885975\tvalid_1's auc: 0.878158\n",
      "[68]\ttraining's auc: 0.886105\tvalid_1's auc: 0.878197\n",
      "[69]\ttraining's auc: 0.886158\tvalid_1's auc: 0.878209\n",
      "[70]\ttraining's auc: 0.886243\tvalid_1's auc: 0.878217\n",
      "[71]\ttraining's auc: 0.88636\tvalid_1's auc: 0.878248\n",
      "[72]\ttraining's auc: 0.886449\tvalid_1's auc: 0.878273\n",
      "[73]\ttraining's auc: 0.886554\tvalid_1's auc: 0.878283\n",
      "[74]\ttraining's auc: 0.886617\tvalid_1's auc: 0.878304\n",
      "[75]\ttraining's auc: 0.886731\tvalid_1's auc: 0.878342\n",
      "[76]\ttraining's auc: 0.886806\tvalid_1's auc: 0.878359\n",
      "[77]\ttraining's auc: 0.886864\tvalid_1's auc: 0.878366\n",
      "[78]\ttraining's auc: 0.887009\tvalid_1's auc: 0.878378\n",
      "[79]\ttraining's auc: 0.887075\tvalid_1's auc: 0.878394\n",
      "[80]\ttraining's auc: 0.88718\tvalid_1's auc: 0.87842\n",
      "[81]\ttraining's auc: 0.887254\tvalid_1's auc: 0.878426\n",
      "[82]\ttraining's auc: 0.887391\tvalid_1's auc: 0.878434\n",
      "[83]\ttraining's auc: 0.887651\tvalid_1's auc: 0.878479\n",
      "[84]\ttraining's auc: 0.887709\tvalid_1's auc: 0.878506\n",
      "[85]\ttraining's auc: 0.887771\tvalid_1's auc: 0.878521\n",
      "[86]\ttraining's auc: 0.887895\tvalid_1's auc: 0.878546\n",
      "[87]\ttraining's auc: 0.887981\tvalid_1's auc: 0.878575\n",
      "[88]\ttraining's auc: 0.888071\tvalid_1's auc: 0.878603\n",
      "[89]\ttraining's auc: 0.888253\tvalid_1's auc: 0.878636\n",
      "[90]\ttraining's auc: 0.888318\tvalid_1's auc: 0.878641\n",
      "[91]\ttraining's auc: 0.888414\tvalid_1's auc: 0.878658\n",
      "[92]\ttraining's auc: 0.888482\tvalid_1's auc: 0.878673\n",
      "[93]\ttraining's auc: 0.888562\tvalid_1's auc: 0.878689\n",
      "[94]\ttraining's auc: 0.888697\tvalid_1's auc: 0.878686\n",
      "[95]\ttraining's auc: 0.888769\tvalid_1's auc: 0.878702\n",
      "[96]\ttraining's auc: 0.888842\tvalid_1's auc: 0.878712\n",
      "[97]\ttraining's auc: 0.888904\tvalid_1's auc: 0.878734\n",
      "[98]\ttraining's auc: 0.888972\tvalid_1's auc: 0.878741\n",
      "[99]\ttraining's auc: 0.889107\tvalid_1's auc: 0.878789\n",
      "[100]\ttraining's auc: 0.889182\tvalid_1's auc: 0.878812\n",
      "[101]\ttraining's auc: 0.88922\tvalid_1's auc: 0.878829\n",
      "[102]\ttraining's auc: 0.889315\tvalid_1's auc: 0.878845\n",
      "[103]\ttraining's auc: 0.889365\tvalid_1's auc: 0.87886\n",
      "[104]\ttraining's auc: 0.88939\tvalid_1's auc: 0.878875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[105]\ttraining's auc: 0.88948\tvalid_1's auc: 0.878864\n",
      "[106]\ttraining's auc: 0.8895\tvalid_1's auc: 0.878875\n",
      "[107]\ttraining's auc: 0.8896\tvalid_1's auc: 0.878892\n",
      "[108]\ttraining's auc: 0.889634\tvalid_1's auc: 0.878897\n",
      "[109]\ttraining's auc: 0.889661\tvalid_1's auc: 0.878918\n",
      "[110]\ttraining's auc: 0.88974\tvalid_1's auc: 0.878923\n",
      "[111]\ttraining's auc: 0.889772\tvalid_1's auc: 0.878941\n",
      "[112]\ttraining's auc: 0.889872\tvalid_1's auc: 0.878952\n",
      "[113]\ttraining's auc: 0.88992\tvalid_1's auc: 0.878962\n",
      "[114]\ttraining's auc: 0.889988\tvalid_1's auc: 0.878941\n",
      "[115]\ttraining's auc: 0.890068\tvalid_1's auc: 0.878955\n",
      "[116]\ttraining's auc: 0.890127\tvalid_1's auc: 0.878964\n",
      "[117]\ttraining's auc: 0.890177\tvalid_1's auc: 0.878977\n",
      "[118]\ttraining's auc: 0.890226\tvalid_1's auc: 0.878993\n",
      "[119]\ttraining's auc: 0.890278\tvalid_1's auc: 0.879\n",
      "[120]\ttraining's auc: 0.890307\tvalid_1's auc: 0.878993\n",
      "[121]\ttraining's auc: 0.890398\tvalid_1's auc: 0.878986\n",
      "[122]\ttraining's auc: 0.890414\tvalid_1's auc: 0.878995\n",
      "[123]\ttraining's auc: 0.890505\tvalid_1's auc: 0.879\n",
      "[124]\ttraining's auc: 0.890528\tvalid_1's auc: 0.879003\n",
      "[125]\ttraining's auc: 0.890568\tvalid_1's auc: 0.879008\n",
      "[126]\ttraining's auc: 0.890647\tvalid_1's auc: 0.879011\n",
      "[127]\ttraining's auc: 0.890688\tvalid_1's auc: 0.879\n",
      "[128]\ttraining's auc: 0.890712\tvalid_1's auc: 0.878998\n",
      "[129]\ttraining's auc: 0.890755\tvalid_1's auc: 0.879001\n",
      "[130]\ttraining's auc: 0.890841\tvalid_1's auc: 0.879014\n",
      "[131]\ttraining's auc: 0.890931\tvalid_1's auc: 0.879038\n",
      "[132]\ttraining's auc: 0.890957\tvalid_1's auc: 0.879039\n",
      "[133]\ttraining's auc: 0.891122\tvalid_1's auc: 0.879047\n",
      "[134]\ttraining's auc: 0.891242\tvalid_1's auc: 0.879044\n",
      "[135]\ttraining's auc: 0.891319\tvalid_1's auc: 0.87905\n",
      "[136]\ttraining's auc: 0.891408\tvalid_1's auc: 0.879058\n",
      "[137]\ttraining's auc: 0.891466\tvalid_1's auc: 0.879049\n",
      "[138]\ttraining's auc: 0.891517\tvalid_1's auc: 0.879039\n",
      "[139]\ttraining's auc: 0.89154\tvalid_1's auc: 0.879037\n",
      "[140]\ttraining's auc: 0.891617\tvalid_1's auc: 0.879027\n",
      "[141]\ttraining's auc: 0.891667\tvalid_1's auc: 0.879011\n",
      "[142]\ttraining's auc: 0.891739\tvalid_1's auc: 0.879013\n",
      "[143]\ttraining's auc: 0.891839\tvalid_1's auc: 0.879005\n",
      "[144]\ttraining's auc: 0.891909\tvalid_1's auc: 0.879014\n",
      "[145]\ttraining's auc: 0.891977\tvalid_1's auc: 0.879016\n",
      "[146]\ttraining's auc: 0.892042\tvalid_1's auc: 0.879019\n",
      "[147]\ttraining's auc: 0.892077\tvalid_1's auc: 0.879023\n",
      "[148]\ttraining's auc: 0.892188\tvalid_1's auc: 0.879033\n",
      "[149]\ttraining's auc: 0.892229\tvalid_1's auc: 0.87904\n",
      "[150]\ttraining's auc: 0.892269\tvalid_1's auc: 0.879051\n",
      "[151]\ttraining's auc: 0.892333\tvalid_1's auc: 0.879032\n",
      "[152]\ttraining's auc: 0.892422\tvalid_1's auc: 0.879024\n",
      "[153]\ttraining's auc: 0.892513\tvalid_1's auc: 0.879006\n",
      "[154]\ttraining's auc: 0.892629\tvalid_1's auc: 0.879001\n",
      "[155]\ttraining's auc: 0.892692\tvalid_1's auc: 0.878997\n",
      "[156]\ttraining's auc: 0.892741\tvalid_1's auc: 0.879004\n",
      "[157]\ttraining's auc: 0.892811\tvalid_1's auc: 0.879021\n",
      "[158]\ttraining's auc: 0.892833\tvalid_1's auc: 0.87902\n",
      "[159]\ttraining's auc: 0.892888\tvalid_1's auc: 0.879027\n",
      "[160]\ttraining's auc: 0.893015\tvalid_1's auc: 0.879031\n",
      "[161]\ttraining's auc: 0.893048\tvalid_1's auc: 0.879039\n",
      "[162]\ttraining's auc: 0.893099\tvalid_1's auc: 0.879048\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[1]\ttraining's auc: 0.873123\tvalid_1's auc: 0.867787\n",
      "[2]\ttraining's auc: 0.873786\tvalid_1's auc: 0.868655\n",
      "[3]\ttraining's auc: 0.875121\tvalid_1's auc: 0.869711\n",
      "[4]\ttraining's auc: 0.875976\tvalid_1's auc: 0.870739\n",
      "[5]\ttraining's auc: 0.876487\tvalid_1's auc: 0.871007\n",
      "[6]\ttraining's auc: 0.877024\tvalid_1's auc: 0.871535\n",
      "[7]\ttraining's auc: 0.877428\tvalid_1's auc: 0.871717\n",
      "[8]\ttraining's auc: 0.877536\tvalid_1's auc: 0.871827\n",
      "[9]\ttraining's auc: 0.877863\tvalid_1's auc: 0.872123\n",
      "[10]\ttraining's auc: 0.878077\tvalid_1's auc: 0.872173\n",
      "[11]\ttraining's auc: 0.878276\tvalid_1's auc: 0.872334\n",
      "[12]\ttraining's auc: 0.878434\tvalid_1's auc: 0.872396\n",
      "[13]\ttraining's auc: 0.878775\tvalid_1's auc: 0.872691\n",
      "[14]\ttraining's auc: 0.8791\tvalid_1's auc: 0.872945\n",
      "[15]\ttraining's auc: 0.879425\tvalid_1's auc: 0.873269\n",
      "[16]\ttraining's auc: 0.87956\tvalid_1's auc: 0.873439\n",
      "[17]\ttraining's auc: 0.879794\tvalid_1's auc: 0.873615\n",
      "[18]\ttraining's auc: 0.880008\tvalid_1's auc: 0.873793\n",
      "[19]\ttraining's auc: 0.88017\tvalid_1's auc: 0.873884\n",
      "[20]\ttraining's auc: 0.880313\tvalid_1's auc: 0.873998\n",
      "[21]\ttraining's auc: 0.880513\tvalid_1's auc: 0.874154\n",
      "[22]\ttraining's auc: 0.880677\tvalid_1's auc: 0.874291\n",
      "[23]\ttraining's auc: 0.880801\tvalid_1's auc: 0.874355\n",
      "[24]\ttraining's auc: 0.880988\tvalid_1's auc: 0.874464\n",
      "[25]\ttraining's auc: 0.881108\tvalid_1's auc: 0.874554\n",
      "[26]\ttraining's auc: 0.881201\tvalid_1's auc: 0.874613\n",
      "[27]\ttraining's auc: 0.881295\tvalid_1's auc: 0.874684\n",
      "[28]\ttraining's auc: 0.881451\tvalid_1's auc: 0.87479\n",
      "[29]\ttraining's auc: 0.881657\tvalid_1's auc: 0.874886\n",
      "[30]\ttraining's auc: 0.881772\tvalid_1's auc: 0.874945\n",
      "[31]\ttraining's auc: 0.881987\tvalid_1's auc: 0.875059\n",
      "[32]\ttraining's auc: 0.882078\tvalid_1's auc: 0.875115\n",
      "[33]\ttraining's auc: 0.882228\tvalid_1's auc: 0.875188\n",
      "[34]\ttraining's auc: 0.882336\tvalid_1's auc: 0.875231\n",
      "[35]\ttraining's auc: 0.88247\tvalid_1's auc: 0.875285\n",
      "[36]\ttraining's auc: 0.882597\tvalid_1's auc: 0.875388\n",
      "[37]\ttraining's auc: 0.882719\tvalid_1's auc: 0.87545\n",
      "[38]\ttraining's auc: 0.882831\tvalid_1's auc: 0.875546\n",
      "[39]\ttraining's auc: 0.882962\tvalid_1's auc: 0.875637\n",
      "[40]\ttraining's auc: 0.88305\tvalid_1's auc: 0.875702\n",
      "[41]\ttraining's auc: 0.883134\tvalid_1's auc: 0.87575\n",
      "[42]\ttraining's auc: 0.883281\tvalid_1's auc: 0.875849\n",
      "[43]\ttraining's auc: 0.883433\tvalid_1's auc: 0.875883\n",
      "[44]\ttraining's auc: 0.883563\tvalid_1's auc: 0.875925\n",
      "[45]\ttraining's auc: 0.883704\tvalid_1's auc: 0.875954\n",
      "[46]\ttraining's auc: 0.88384\tvalid_1's auc: 0.876036\n",
      "[47]\ttraining's auc: 0.883978\tvalid_1's auc: 0.876116\n",
      "[48]\ttraining's auc: 0.884111\tvalid_1's auc: 0.876159\n",
      "[49]\ttraining's auc: 0.884211\tvalid_1's auc: 0.8762\n",
      "[50]\ttraining's auc: 0.884329\tvalid_1's auc: 0.876276\n",
      "[51]\ttraining's auc: 0.884445\tvalid_1's auc: 0.876326\n",
      "[52]\ttraining's auc: 0.884579\tvalid_1's auc: 0.876347\n",
      "[53]\ttraining's auc: 0.884709\tvalid_1's auc: 0.876365\n",
      "[54]\ttraining's auc: 0.884822\tvalid_1's auc: 0.876417\n",
      "[55]\ttraining's auc: 0.884933\tvalid_1's auc: 0.876474\n",
      "[56]\ttraining's auc: 0.885038\tvalid_1's auc: 0.876508\n",
      "[57]\ttraining's auc: 0.885161\tvalid_1's auc: 0.876557\n",
      "[58]\ttraining's auc: 0.885308\tvalid_1's auc: 0.876637\n",
      "[59]\ttraining's auc: 0.885394\tvalid_1's auc: 0.876658\n",
      "[60]\ttraining's auc: 0.885554\tvalid_1's auc: 0.876705\n",
      "[61]\ttraining's auc: 0.885612\tvalid_1's auc: 0.876729\n",
      "[62]\ttraining's auc: 0.885672\tvalid_1's auc: 0.876766\n",
      "[63]\ttraining's auc: 0.885787\tvalid_1's auc: 0.876805\n",
      "[64]\ttraining's auc: 0.885849\tvalid_1's auc: 0.876833\n",
      "[65]\ttraining's auc: 0.885924\tvalid_1's auc: 0.876845\n",
      "[66]\ttraining's auc: 0.885982\tvalid_1's auc: 0.876857\n",
      "[67]\ttraining's auc: 0.886058\tvalid_1's auc: 0.876873\n",
      "[68]\ttraining's auc: 0.88612\tvalid_1's auc: 0.876889\n",
      "[69]\ttraining's auc: 0.886241\tvalid_1's auc: 0.876937\n",
      "[70]\ttraining's auc: 0.88632\tvalid_1's auc: 0.876952\n",
      "[71]\ttraining's auc: 0.886437\tvalid_1's auc: 0.876995\n",
      "[72]\ttraining's auc: 0.886506\tvalid_1's auc: 0.87701\n",
      "[73]\ttraining's auc: 0.886647\tvalid_1's auc: 0.877018\n",
      "[74]\ttraining's auc: 0.886745\tvalid_1's auc: 0.877039\n",
      "[75]\ttraining's auc: 0.886842\tvalid_1's auc: 0.877076\n",
      "[76]\ttraining's auc: 0.886925\tvalid_1's auc: 0.877084\n",
      "[77]\ttraining's auc: 0.887002\tvalid_1's auc: 0.877109\n",
      "[78]\ttraining's auc: 0.887084\tvalid_1's auc: 0.877147\n",
      "[79]\ttraining's auc: 0.887182\tvalid_1's auc: 0.87715\n",
      "[80]\ttraining's auc: 0.887349\tvalid_1's auc: 0.877174\n",
      "[81]\ttraining's auc: 0.887403\tvalid_1's auc: 0.877178\n",
      "[82]\ttraining's auc: 0.887494\tvalid_1's auc: 0.877202\n",
      "[83]\ttraining's auc: 0.887622\tvalid_1's auc: 0.877239\n",
      "[84]\ttraining's auc: 0.887763\tvalid_1's auc: 0.877281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[85]\ttraining's auc: 0.887959\tvalid_1's auc: 0.877327\n",
      "[86]\ttraining's auc: 0.888099\tvalid_1's auc: 0.877327\n",
      "[87]\ttraining's auc: 0.888204\tvalid_1's auc: 0.877334\n",
      "[88]\ttraining's auc: 0.888229\tvalid_1's auc: 0.877355\n",
      "[89]\ttraining's auc: 0.888274\tvalid_1's auc: 0.877358\n",
      "[90]\ttraining's auc: 0.888357\tvalid_1's auc: 0.877352\n",
      "[91]\ttraining's auc: 0.888449\tvalid_1's auc: 0.877357\n",
      "[92]\ttraining's auc: 0.888588\tvalid_1's auc: 0.877369\n",
      "[93]\ttraining's auc: 0.888655\tvalid_1's auc: 0.877408\n",
      "[94]\ttraining's auc: 0.888784\tvalid_1's auc: 0.877442\n",
      "[95]\ttraining's auc: 0.888852\tvalid_1's auc: 0.877439\n",
      "[96]\ttraining's auc: 0.888922\tvalid_1's auc: 0.877472\n",
      "[97]\ttraining's auc: 0.888979\tvalid_1's auc: 0.8775\n",
      "[98]\ttraining's auc: 0.889032\tvalid_1's auc: 0.877507\n",
      "[99]\ttraining's auc: 0.889074\tvalid_1's auc: 0.877505\n",
      "[100]\ttraining's auc: 0.889191\tvalid_1's auc: 0.87752\n",
      "[101]\ttraining's auc: 0.889259\tvalid_1's auc: 0.877545\n",
      "[102]\ttraining's auc: 0.889336\tvalid_1's auc: 0.877574\n",
      "[103]\ttraining's auc: 0.889444\tvalid_1's auc: 0.87759\n",
      "[104]\ttraining's auc: 0.889505\tvalid_1's auc: 0.877607\n",
      "[105]\ttraining's auc: 0.889554\tvalid_1's auc: 0.877612\n",
      "[106]\ttraining's auc: 0.889654\tvalid_1's auc: 0.877615\n",
      "[107]\ttraining's auc: 0.889723\tvalid_1's auc: 0.87764\n",
      "[108]\ttraining's auc: 0.889753\tvalid_1's auc: 0.877659\n",
      "[109]\ttraining's auc: 0.889807\tvalid_1's auc: 0.877685\n",
      "[110]\ttraining's auc: 0.889839\tvalid_1's auc: 0.877684\n",
      "[111]\ttraining's auc: 0.889901\tvalid_1's auc: 0.877687\n",
      "[112]\ttraining's auc: 0.889994\tvalid_1's auc: 0.877696\n",
      "[113]\ttraining's auc: 0.890068\tvalid_1's auc: 0.877693\n",
      "[114]\ttraining's auc: 0.890254\tvalid_1's auc: 0.87772\n",
      "[115]\ttraining's auc: 0.890281\tvalid_1's auc: 0.877701\n",
      "[116]\ttraining's auc: 0.890345\tvalid_1's auc: 0.877691\n",
      "[117]\ttraining's auc: 0.890427\tvalid_1's auc: 0.877711\n",
      "[118]\ttraining's auc: 0.890454\tvalid_1's auc: 0.877713\n",
      "[119]\ttraining's auc: 0.890583\tvalid_1's auc: 0.877716\n",
      "[120]\ttraining's auc: 0.890622\tvalid_1's auc: 0.877727\n",
      "[121]\ttraining's auc: 0.890791\tvalid_1's auc: 0.877718\n",
      "[122]\ttraining's auc: 0.890905\tvalid_1's auc: 0.877709\n",
      "[123]\ttraining's auc: 0.89097\tvalid_1's auc: 0.877715\n",
      "[124]\ttraining's auc: 0.891049\tvalid_1's auc: 0.877718\n",
      "[125]\ttraining's auc: 0.891079\tvalid_1's auc: 0.877718\n",
      "[126]\ttraining's auc: 0.891133\tvalid_1's auc: 0.877727\n",
      "[127]\ttraining's auc: 0.891165\tvalid_1's auc: 0.877736\n",
      "[128]\ttraining's auc: 0.891256\tvalid_1's auc: 0.877753\n",
      "[129]\ttraining's auc: 0.891336\tvalid_1's auc: 0.877752\n",
      "[130]\ttraining's auc: 0.891366\tvalid_1's auc: 0.877764\n",
      "[131]\ttraining's auc: 0.891461\tvalid_1's auc: 0.877773\n",
      "[132]\ttraining's auc: 0.891512\tvalid_1's auc: 0.877792\n",
      "[133]\ttraining's auc: 0.891622\tvalid_1's auc: 0.877802\n",
      "[134]\ttraining's auc: 0.89179\tvalid_1's auc: 0.877811\n",
      "[135]\ttraining's auc: 0.891819\tvalid_1's auc: 0.877803\n",
      "[136]\ttraining's auc: 0.891867\tvalid_1's auc: 0.877812\n",
      "[137]\ttraining's auc: 0.891998\tvalid_1's auc: 0.877803\n",
      "[138]\ttraining's auc: 0.892135\tvalid_1's auc: 0.8778\n",
      "[139]\ttraining's auc: 0.892247\tvalid_1's auc: 0.877813\n",
      "[140]\ttraining's auc: 0.892334\tvalid_1's auc: 0.877814\n",
      "[141]\ttraining's auc: 0.892359\tvalid_1's auc: 0.877823\n",
      "[142]\ttraining's auc: 0.892461\tvalid_1's auc: 0.877831\n",
      "[143]\ttraining's auc: 0.892538\tvalid_1's auc: 0.877825\n",
      "[144]\ttraining's auc: 0.89261\tvalid_1's auc: 0.877834\n",
      "[145]\ttraining's auc: 0.892659\tvalid_1's auc: 0.87783\n",
      "[146]\ttraining's auc: 0.892744\tvalid_1's auc: 0.877844\n",
      "[147]\ttraining's auc: 0.892859\tvalid_1's auc: 0.877846\n",
      "[148]\ttraining's auc: 0.892895\tvalid_1's auc: 0.877849\n",
      "[149]\ttraining's auc: 0.892969\tvalid_1's auc: 0.877861\n",
      "[150]\ttraining's auc: 0.89304\tvalid_1's auc: 0.877847\n",
      "[151]\ttraining's auc: 0.893073\tvalid_1's auc: 0.877842\n",
      "[152]\ttraining's auc: 0.893168\tvalid_1's auc: 0.877853\n",
      "[153]\ttraining's auc: 0.893241\tvalid_1's auc: 0.877851\n",
      "[154]\ttraining's auc: 0.8933\tvalid_1's auc: 0.87786\n",
      "[155]\ttraining's auc: 0.893332\tvalid_1's auc: 0.877857\n",
      "[156]\ttraining's auc: 0.893435\tvalid_1's auc: 0.877845\n",
      "[157]\ttraining's auc: 0.893463\tvalid_1's auc: 0.877845\n",
      "[158]\ttraining's auc: 0.893546\tvalid_1's auc: 0.87784\n",
      "[159]\ttraining's auc: 0.893657\tvalid_1's auc: 0.877846\n",
      "[160]\ttraining's auc: 0.893758\tvalid_1's auc: 0.877827\n",
      "[161]\ttraining's auc: 0.893814\tvalid_1's auc: 0.87785\n",
      "[162]\ttraining's auc: 0.893911\tvalid_1's auc: 0.877845\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[1]\ttraining's auc: 0.872419\tvalid_1's auc: 0.8716\n",
      "[2]\ttraining's auc: 0.87387\tvalid_1's auc: 0.873061\n",
      "[3]\ttraining's auc: 0.874092\tvalid_1's auc: 0.873513\n",
      "[4]\ttraining's auc: 0.874602\tvalid_1's auc: 0.873959\n",
      "[5]\ttraining's auc: 0.875539\tvalid_1's auc: 0.874742\n",
      "[6]\ttraining's auc: 0.876114\tvalid_1's auc: 0.875236\n",
      "[7]\ttraining's auc: 0.876623\tvalid_1's auc: 0.875583\n",
      "[8]\ttraining's auc: 0.876881\tvalid_1's auc: 0.875871\n",
      "[9]\ttraining's auc: 0.877223\tvalid_1's auc: 0.876183\n",
      "[10]\ttraining's auc: 0.877453\tvalid_1's auc: 0.876398\n",
      "[11]\ttraining's auc: 0.877836\tvalid_1's auc: 0.876674\n",
      "[12]\ttraining's auc: 0.877958\tvalid_1's auc: 0.876738\n",
      "[13]\ttraining's auc: 0.878225\tvalid_1's auc: 0.876943\n",
      "[14]\ttraining's auc: 0.878434\tvalid_1's auc: 0.877039\n",
      "[15]\ttraining's auc: 0.878591\tvalid_1's auc: 0.877184\n",
      "[16]\ttraining's auc: 0.878732\tvalid_1's auc: 0.87726\n",
      "[17]\ttraining's auc: 0.878969\tvalid_1's auc: 0.8774\n",
      "[18]\ttraining's auc: 0.879107\tvalid_1's auc: 0.877527\n",
      "[19]\ttraining's auc: 0.87927\tvalid_1's auc: 0.877645\n",
      "[20]\ttraining's auc: 0.879444\tvalid_1's auc: 0.877787\n",
      "[21]\ttraining's auc: 0.879629\tvalid_1's auc: 0.877935\n",
      "[22]\ttraining's auc: 0.879784\tvalid_1's auc: 0.878071\n",
      "[23]\ttraining's auc: 0.87997\tvalid_1's auc: 0.878199\n",
      "[24]\ttraining's auc: 0.88009\tvalid_1's auc: 0.878271\n",
      "[25]\ttraining's auc: 0.880193\tvalid_1's auc: 0.878333\n",
      "[26]\ttraining's auc: 0.880311\tvalid_1's auc: 0.878407\n",
      "[27]\ttraining's auc: 0.880429\tvalid_1's auc: 0.878462\n",
      "[28]\ttraining's auc: 0.880587\tvalid_1's auc: 0.87854\n",
      "[29]\ttraining's auc: 0.880683\tvalid_1's auc: 0.878593\n",
      "[30]\ttraining's auc: 0.880809\tvalid_1's auc: 0.878651\n",
      "[31]\ttraining's auc: 0.880942\tvalid_1's auc: 0.878714\n",
      "[32]\ttraining's auc: 0.881181\tvalid_1's auc: 0.878873\n",
      "[33]\ttraining's auc: 0.881312\tvalid_1's auc: 0.878969\n",
      "[34]\ttraining's auc: 0.881508\tvalid_1's auc: 0.879114\n",
      "[35]\ttraining's auc: 0.881642\tvalid_1's auc: 0.879171\n",
      "[36]\ttraining's auc: 0.881747\tvalid_1's auc: 0.879198\n",
      "[37]\ttraining's auc: 0.881856\tvalid_1's auc: 0.879255\n",
      "[38]\ttraining's auc: 0.881941\tvalid_1's auc: 0.879321\n",
      "[39]\ttraining's auc: 0.88207\tvalid_1's auc: 0.879381\n",
      "[40]\ttraining's auc: 0.882207\tvalid_1's auc: 0.879472\n",
      "[41]\ttraining's auc: 0.88231\tvalid_1's auc: 0.879517\n",
      "[42]\ttraining's auc: 0.882419\tvalid_1's auc: 0.879569\n",
      "[43]\ttraining's auc: 0.882517\tvalid_1's auc: 0.879624\n",
      "[44]\ttraining's auc: 0.882665\tvalid_1's auc: 0.879673\n",
      "[45]\ttraining's auc: 0.882762\tvalid_1's auc: 0.879734\n",
      "[46]\ttraining's auc: 0.882886\tvalid_1's auc: 0.879768\n",
      "[47]\ttraining's auc: 0.883045\tvalid_1's auc: 0.879824\n",
      "[48]\ttraining's auc: 0.883172\tvalid_1's auc: 0.879847\n",
      "[49]\ttraining's auc: 0.883313\tvalid_1's auc: 0.879883\n",
      "[50]\ttraining's auc: 0.883403\tvalid_1's auc: 0.8799\n",
      "[51]\ttraining's auc: 0.883475\tvalid_1's auc: 0.879906\n",
      "[52]\ttraining's auc: 0.88363\tvalid_1's auc: 0.87995\n",
      "[53]\ttraining's auc: 0.883788\tvalid_1's auc: 0.880028\n",
      "[54]\ttraining's auc: 0.883879\tvalid_1's auc: 0.88007\n",
      "[55]\ttraining's auc: 0.884007\tvalid_1's auc: 0.880095\n",
      "[56]\ttraining's auc: 0.884085\tvalid_1's auc: 0.880111\n",
      "[57]\ttraining's auc: 0.88423\tvalid_1's auc: 0.880144\n",
      "[58]\ttraining's auc: 0.884374\tvalid_1's auc: 0.880203\n",
      "[59]\ttraining's auc: 0.884576\tvalid_1's auc: 0.880285\n",
      "[60]\ttraining's auc: 0.884658\tvalid_1's auc: 0.880317\n",
      "[61]\ttraining's auc: 0.884776\tvalid_1's auc: 0.880327\n",
      "[62]\ttraining's auc: 0.884876\tvalid_1's auc: 0.880359\n",
      "[63]\ttraining's auc: 0.88495\tvalid_1's auc: 0.880413\n",
      "[64]\ttraining's auc: 0.885105\tvalid_1's auc: 0.880459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[65]\ttraining's auc: 0.885158\tvalid_1's auc: 0.880475\n",
      "[66]\ttraining's auc: 0.885265\tvalid_1's auc: 0.880511\n",
      "[67]\ttraining's auc: 0.885331\tvalid_1's auc: 0.880532\n",
      "[68]\ttraining's auc: 0.885498\tvalid_1's auc: 0.880572\n",
      "[69]\ttraining's auc: 0.88563\tvalid_1's auc: 0.880628\n",
      "[70]\ttraining's auc: 0.885749\tvalid_1's auc: 0.880681\n",
      "[71]\ttraining's auc: 0.885836\tvalid_1's auc: 0.880736\n",
      "[72]\ttraining's auc: 0.8859\tvalid_1's auc: 0.88076\n",
      "[73]\ttraining's auc: 0.886012\tvalid_1's auc: 0.880779\n",
      "[74]\ttraining's auc: 0.886087\tvalid_1's auc: 0.880813\n",
      "[75]\ttraining's auc: 0.886169\tvalid_1's auc: 0.880843\n",
      "[76]\ttraining's auc: 0.886327\tvalid_1's auc: 0.880902\n",
      "[77]\ttraining's auc: 0.886486\tvalid_1's auc: 0.88099\n",
      "[78]\ttraining's auc: 0.886566\tvalid_1's auc: 0.881006\n",
      "[79]\ttraining's auc: 0.886706\tvalid_1's auc: 0.881074\n",
      "[80]\ttraining's auc: 0.886825\tvalid_1's auc: 0.881095\n",
      "[81]\ttraining's auc: 0.886977\tvalid_1's auc: 0.881147\n",
      "[82]\ttraining's auc: 0.887079\tvalid_1's auc: 0.881176\n",
      "[83]\ttraining's auc: 0.887164\tvalid_1's auc: 0.881189\n",
      "[84]\ttraining's auc: 0.887247\tvalid_1's auc: 0.881187\n",
      "[85]\ttraining's auc: 0.887416\tvalid_1's auc: 0.881245\n",
      "[86]\ttraining's auc: 0.887555\tvalid_1's auc: 0.88127\n",
      "[87]\ttraining's auc: 0.88767\tvalid_1's auc: 0.881277\n",
      "[88]\ttraining's auc: 0.887724\tvalid_1's auc: 0.881296\n",
      "[89]\ttraining's auc: 0.887811\tvalid_1's auc: 0.881331\n",
      "[90]\ttraining's auc: 0.887895\tvalid_1's auc: 0.881369\n",
      "[91]\ttraining's auc: 0.887948\tvalid_1's auc: 0.881394\n",
      "[92]\ttraining's auc: 0.888027\tvalid_1's auc: 0.881417\n",
      "[93]\ttraining's auc: 0.888079\tvalid_1's auc: 0.88145\n",
      "[94]\ttraining's auc: 0.888135\tvalid_1's auc: 0.88146\n",
      "[95]\ttraining's auc: 0.888207\tvalid_1's auc: 0.881488\n",
      "[96]\ttraining's auc: 0.888324\tvalid_1's auc: 0.881495\n",
      "[97]\ttraining's auc: 0.888351\tvalid_1's auc: 0.881513\n",
      "[98]\ttraining's auc: 0.888414\tvalid_1's auc: 0.881542\n",
      "[99]\ttraining's auc: 0.888443\tvalid_1's auc: 0.881547\n",
      "[100]\ttraining's auc: 0.888524\tvalid_1's auc: 0.881564\n",
      "[101]\ttraining's auc: 0.888624\tvalid_1's auc: 0.881586\n",
      "[102]\ttraining's auc: 0.888757\tvalid_1's auc: 0.881597\n",
      "[103]\ttraining's auc: 0.888814\tvalid_1's auc: 0.881604\n",
      "[104]\ttraining's auc: 0.888896\tvalid_1's auc: 0.881629\n",
      "[105]\ttraining's auc: 0.888915\tvalid_1's auc: 0.88164\n",
      "[106]\ttraining's auc: 0.889\tvalid_1's auc: 0.881632\n",
      "[107]\ttraining's auc: 0.889053\tvalid_1's auc: 0.881641\n",
      "[108]\ttraining's auc: 0.889071\tvalid_1's auc: 0.881638\n",
      "[109]\ttraining's auc: 0.889175\tvalid_1's auc: 0.881662\n",
      "[110]\ttraining's auc: 0.889198\tvalid_1's auc: 0.881669\n",
      "[111]\ttraining's auc: 0.889232\tvalid_1's auc: 0.881665\n",
      "[112]\ttraining's auc: 0.889266\tvalid_1's auc: 0.88167\n",
      "[113]\ttraining's auc: 0.889318\tvalid_1's auc: 0.881676\n",
      "[114]\ttraining's auc: 0.889372\tvalid_1's auc: 0.881687\n",
      "[115]\ttraining's auc: 0.88939\tvalid_1's auc: 0.881696\n",
      "[116]\ttraining's auc: 0.889443\tvalid_1's auc: 0.881708\n",
      "[117]\ttraining's auc: 0.889595\tvalid_1's auc: 0.881749\n",
      "[118]\ttraining's auc: 0.889724\tvalid_1's auc: 0.881759\n",
      "[119]\ttraining's auc: 0.889837\tvalid_1's auc: 0.881767\n",
      "[120]\ttraining's auc: 0.889874\tvalid_1's auc: 0.881773\n",
      "[121]\ttraining's auc: 0.889931\tvalid_1's auc: 0.881782\n",
      "[122]\ttraining's auc: 0.889973\tvalid_1's auc: 0.881787\n",
      "[123]\ttraining's auc: 0.89003\tvalid_1's auc: 0.88179\n",
      "[124]\ttraining's auc: 0.890126\tvalid_1's auc: 0.881806\n",
      "[125]\ttraining's auc: 0.890175\tvalid_1's auc: 0.881815\n",
      "[126]\ttraining's auc: 0.890227\tvalid_1's auc: 0.881827\n",
      "[127]\ttraining's auc: 0.890262\tvalid_1's auc: 0.881836\n",
      "[128]\ttraining's auc: 0.890288\tvalid_1's auc: 0.881846\n",
      "[129]\ttraining's auc: 0.890315\tvalid_1's auc: 0.881858\n",
      "[130]\ttraining's auc: 0.890342\tvalid_1's auc: 0.881864\n",
      "[131]\ttraining's auc: 0.890527\tvalid_1's auc: 0.88187\n",
      "[132]\ttraining's auc: 0.890552\tvalid_1's auc: 0.881872\n",
      "[133]\ttraining's auc: 0.890574\tvalid_1's auc: 0.881872\n",
      "[134]\ttraining's auc: 0.890719\tvalid_1's auc: 0.881888\n",
      "[135]\ttraining's auc: 0.890825\tvalid_1's auc: 0.881879\n",
      "[136]\ttraining's auc: 0.890895\tvalid_1's auc: 0.881885\n",
      "[137]\ttraining's auc: 0.890994\tvalid_1's auc: 0.881884\n",
      "[138]\ttraining's auc: 0.891022\tvalid_1's auc: 0.881898\n",
      "[139]\ttraining's auc: 0.891116\tvalid_1's auc: 0.881892\n",
      "[140]\ttraining's auc: 0.891197\tvalid_1's auc: 0.881888\n",
      "[141]\ttraining's auc: 0.891241\tvalid_1's auc: 0.881897\n",
      "[142]\ttraining's auc: 0.891294\tvalid_1's auc: 0.88188\n",
      "[143]\ttraining's auc: 0.89136\tvalid_1's auc: 0.88188\n",
      "[144]\ttraining's auc: 0.891378\tvalid_1's auc: 0.881878\n",
      "[145]\ttraining's auc: 0.891548\tvalid_1's auc: 0.881863\n",
      "[146]\ttraining's auc: 0.891566\tvalid_1's auc: 0.881868\n",
      "[147]\ttraining's auc: 0.891604\tvalid_1's auc: 0.881879\n",
      "[148]\ttraining's auc: 0.8918\tvalid_1's auc: 0.88187\n",
      "[149]\ttraining's auc: 0.891823\tvalid_1's auc: 0.881872\n",
      "[150]\ttraining's auc: 0.891925\tvalid_1's auc: 0.88187\n",
      "[151]\ttraining's auc: 0.89206\tvalid_1's auc: 0.881873\n",
      "[152]\ttraining's auc: 0.892155\tvalid_1's auc: 0.88188\n",
      "[153]\ttraining's auc: 0.892194\tvalid_1's auc: 0.881884\n",
      "[154]\ttraining's auc: 0.892217\tvalid_1's auc: 0.881886\n",
      "[155]\ttraining's auc: 0.89224\tvalid_1's auc: 0.881885\n",
      "[156]\ttraining's auc: 0.892273\tvalid_1's auc: 0.881898\n",
      "[157]\ttraining's auc: 0.892293\tvalid_1's auc: 0.881905\n",
      "[158]\ttraining's auc: 0.8923\tvalid_1's auc: 0.881904\n",
      "[159]\ttraining's auc: 0.892504\tvalid_1's auc: 0.881908\n",
      "[160]\ttraining's auc: 0.892675\tvalid_1's auc: 0.881913\n",
      "[161]\ttraining's auc: 0.89269\tvalid_1's auc: 0.881911\n",
      "[162]\ttraining's auc: 0.89271\tvalid_1's auc: 0.881911\n",
      "the number of probability more than 0.00 is 200000:\n",
      "the ratio of probability more than 0.00 is : 1.0000\n",
      "---------------------------------------------------\n",
      "\n",
      "the number of probability more than 0.10 is 97869:\n",
      "the ratio of probability more than 0.10 is : 0.4893\n",
      "---------------------------------------------------\n",
      "\n",
      "the number of probability more than 0.20 is 88564:\n",
      "the ratio of probability more than 0.20 is : 0.4428\n",
      "---------------------------------------------------\n",
      "\n",
      "the number of probability more than 0.30 is 82075:\n",
      "the ratio of probability more than 0.30 is : 0.4104\n",
      "---------------------------------------------------\n",
      "\n",
      "the number of probability more than 0.40 is 74315:\n",
      "the ratio of probability more than 0.40 is : 0.3716\n",
      "---------------------------------------------------\n",
      "\n",
      "the number of probability more than 0.50 is 65662:\n",
      "the ratio of probability more than 0.50 is : 0.3283\n",
      "---------------------------------------------------\n",
      "\n",
      "the number of probability more than 0.60 is 56273:\n",
      "the ratio of probability more than 0.60 is : 0.2814\n",
      "---------------------------------------------------\n",
      "\n",
      "the number of probability more than 0.70 is 37892:\n",
      "the ratio of probability more than 0.70 is : 0.1895\n",
      "---------------------------------------------------\n",
      "\n",
      "the number of probability more than 0.80 is 11681:\n",
      "the ratio of probability more than 0.80 is : 0.0584\n",
      "---------------------------------------------------\n",
      "\n",
      "the number of probability more than 0.90 is 2846:\n",
      "the ratio of probability more than 0.90 is : 0.0142\n",
      "---------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Executing...\")\n",
    "Y_exam = np.zeros(X_exam_processed.shape[0])\n",
    "k = 5\n",
    "kf = StratifiedKFold(n_splits=k)\n",
    "for tr_index, val_index in kf.split(X_processed,Y_model):\n",
    "    X_tr,Y_tr = X_processed.iloc[tr_index],Y_model.iloc[tr_index]\n",
    "    X_val, Y_val = X_processed.iloc[val_index],Y_model.iloc[val_index]\n",
    "    \n",
    "    optimized_LGBM.fit(X_tr,Y_tr,eval_metric='auc',eval_set=[(X_tr,Y_tr),(X_val,Y_val)])\n",
    "    proba = optimized_LGBM.predict_proba(X_exam_processed)[:,1]\n",
    "    Y_exam = Y_exam + proba\n",
    "Y_exam = Y_exam/k\n",
    "thresholds = np.array([0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9])\n",
    "# the ratio of high prob with different thresholds\n",
    "for num in thresholds: \n",
    "    filtered = Y_exam[np.where(Y_exam>=num)]\n",
    "    print(\"the number of probability more than %.2f is %d:\" %(num,len(filtered)))\n",
    "    print(\"the ratio of probability more than %.2f is : %.4f\"%(num, float(len(filtered))/len(Y_exam)))\n",
    "    print('---------------------------------------------------\\n')\n",
    "# res = pd.DataFrame({'business prob':Y_exam})\n",
    "# res.to_csv(\"./part1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "310bd2f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=759, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=759\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.5748112729766246, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5748112729766246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.39335063783856505, subsample=1.0 will be ignored. Current value: bagging_fraction=0.39335063783856505\n",
      "[LightGBM] [Warning] lambda_l2 is set=8.86176475299599, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.86176475299599\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "Y_exam = np.zeros(X_exam_processed.shape[0])\n",
    "\n",
    "accuracy_Arr = np.array([])\n",
    "popup_Arr = np.array([])\n",
    "survey_Arr = np.array([])\n",
    "\n",
    "k = 5\n",
    "kf = StratifiedKFold(n_splits=k)\n",
    "thresholds = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "for th in thresholds:\n",
    "    popup_P = 0\n",
    "    survey_P = 0\n",
    "    accuracy = 0\n",
    "    for tr_index, val_index in kf.split(X_processed,Y_model):\n",
    "        X_tr,Y_tr = X_processed.iloc[tr_index],Y_model.iloc[tr_index]\n",
    "        X_val, Y_val = X_processed.iloc[val_index],Y_model.iloc[val_index]\n",
    "\n",
    "        optimized_LGBM.fit(X_tr,Y_tr,eval_metric='auc')\n",
    "        # Generate the columns\n",
    "        proba = optimized_LGBM.predict_proba(X_val)[:,1]\n",
    "        pred = pd.DataFrame({'business prob_pred':proba})\n",
    "        popup = pd.DataFrame({'popup':np.zeros(X_val.shape[0])})\n",
    "        survey = pd.DataFrame({'survey':np.zeros(X_val.shape[0])})\n",
    "        # Merge\n",
    "        res = pd.concat([pred,popup],axis=1)\n",
    "        res = pd.concat([res,survey],axis=1)\n",
    "        \n",
    "        # If predicted proba is more than th, put his popup as 1\n",
    "        res.loc[res['business prob_pred'] >= th, 'popup'] = 1\n",
    "        res.loc[res['business prob_pred'] >= th, 'survey'] = 1\n",
    "        \n",
    "        accuracy += accuracy_score(Y_val, res['popup'])\n",
    "        res = pd.concat([res,Y_val.reset_index(drop=True)],axis=1) # Merge res with Y_val\n",
    "        popup_P += res.loc[res['popup']==1,'business'].sum()*(500000*0.01) - res['popup'].sum()*400\n",
    "        survey_P += res.loc[res['survey']==1,'business'].sum()*(500000*0.036) - res['survey'].sum()*5000\n",
    "        \n",
    "    accuracy_Arr = np.append(accuracy_Arr,accuracy/k)\n",
    "    popup_Arr = np.append(popup_Arr,popup_P/k)\n",
    "    survey_Arr = np.append(survey_Arr,survey_P/k)\n",
    "    \n",
    "\n",
    "#     print('---------------------------------')\n",
    "#     print(accuracy_score(Y_val, res['popup']))\n",
    "#     print('---------------------------------')\n",
    "#     print('net profit:')\n",
    "#     profit = res.loc[res['popup']==1,'business'].sum()*(500000*0.01) - res['popup'].sum()*400\n",
    "#     print(profit)\n",
    "#     print('---------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9a8b608e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   threshold  avg_Accuracy  avg_Popup_Profit  avg_Survey_Porfit\n",
      "0        0.0      0.065395       -11683600.0       -611657400.0\n",
      "1        0.1      0.576526        20730360.0       -203323400.0\n",
      "2        0.2      0.619848        23054360.0       -169520800.0\n",
      "3        0.3      0.651412        24557000.0       -145255400.0\n",
      "4        0.4      0.686819        25834400.0       -118812600.0\n",
      "5        0.5      0.724812        26625400.0        -91543400.0\n",
      "6        0.6      0.764071        26434840.0        -65285200.0\n",
      "7        0.7      0.833134        23025200.0        -24948800.0\n",
      "8        0.8      0.915878        12848000.0         11774200.0\n",
      "9        0.9      0.935575         5281000.0         10716800.0\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'threshold':thresholds, 'avg_Accuracy':accuracy_Arr, 'avg_Popup_Profit':popup_Arr, 'avg_Survey_Porfit':survey_Arr})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0bffe015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   threshold  avg_accuracy  avg_profit\n",
      "0        0.0      0.065395 -11683600.0\n",
      "1        0.1      0.576526  20730360.0\n",
      "2        0.2      0.619848  23054360.0\n",
      "3        0.3      0.651412  24557000.0\n",
      "4        0.4      0.686819  25834400.0\n",
      "5        0.5      0.724812  26625400.0\n",
      "6        0.6      0.764071  26434840.0\n",
      "7        0.7      0.833134  23025200.0\n",
      "8        0.8      0.915878  12848000.0\n",
      "9        0.9      0.935575   5281000.0\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'threshold':thresholds, 'avg_Accuracy':accuracy_Arr, 'avg_Popup_Profit':popup_Arr, 'avg_Survey_Porfit':survey_Arr})\n",
    "df.set_index('threshold')\n",
    "print(df)\n",
    "# 정확도 72% 일때 \n",
    "# False Positive만 고려했을때,  약140명에게 popup -> 사실 그 중 100명만이 소상공인\n",
    "# 대충 야매로 계산시, 100*0.01*500000 - 400*140 = 444000\n",
    "# 근데 이 table이 80만/5 =16만명에 대한 평균적인 validation 이니까\n",
    "# 16만명중 6.5% 인 10400명이 실제 소상공인\n",
    "# 16만명중 32%의 사람들에게 뿌리면 51200명\n",
    "# 10400명이 51200안에 들어가 있다고 가정...\n",
    "# 10400*0.01*50만 - 400*51200 = 31520000\n",
    "# False Negative 까지 고려했을 대 아마 비슷하지 않을까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627b1a21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca758060",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
